{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "I4rykGHz0f0e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "# Ignore Warning message\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Random seed fix\n",
        "import os\n",
        "import random\n",
        "\n",
        "# progress bar in repeated code\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "# Scoring\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Model\n",
        "import catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# !pip install catboost\n",
        "import catboost\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(37) # Seed 고정\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Class', 'Y_Quality'])\n",
        "train_y = train_df['Y_Class']\n",
        "\n",
        "test = test_df.drop(columns=['PRODUCT_ID'])"
      ],
      "metadata": {
        "id": "ab7Y3rhSi0V-"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing - Imputer"
      ],
      "metadata": {
        "id": "NudKM-oaDQ9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# qualitative to quantitative\n",
        "qual_col = ['LINE', 'PRODUCT_CODE']\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "    \n",
        "    for label in np.unique(test[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test[i] = le.transform(test[i]) \n",
        "print('Done.')    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR7OmmLqmMcJ",
        "outputId": "e5144018-e0f2-46ec-e14f-176b253c2809"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normlize\n",
        "# different sacles of data will lead the KNN Imputer to genrate biased replacements\n",
        "\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "# train_x = pd.DataFrame(scaler.fit_transform(train_x))\n",
        "# test_x = pd.DataFrame(scaler.transform(test_x))"
      ],
      "metadata": {
        "id": "HexhfvDW0f_J"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "Gu20N-wZgpiG"
      },
      "outputs": [],
      "source": [
        "# KNN Imputer \n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Define columns with missing values\n",
        "missing_cols = ['X_{}'.format(i) for i in range(1, 3327)]\n",
        "\n",
        "# Impute missing values using KNN imputer on train data\n",
        "imputer = KNNImputer(n_neighbors=5)   # n_neighbors: params\n",
        "imputer.fit(train_x)\n",
        "                                 \n",
        "train_x = imputer.transform(train_x)    \n",
        "test_x = imputer.transform(test)   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = pd.DataFrame(train_x)\n",
        "test_x = pd.DataFrame(test)\n",
        "train_x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "XYbddpgzkJwE",
        "outputId": "f64d655a-ff9c-46fa-afdc-001e3f2d2fb9"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     ...      3244  \\\n",
              "0   4.0   2.0   2.0  95.0   0.0  45.0  10.0   0.0  45.0  10.0  ...  0.000008   \n",
              "1   5.0   2.0   2.0  96.0   0.0  45.0  10.0   0.0  53.0  10.0  ...  0.000008   \n",
              "2   5.0   2.0   2.0  95.0   0.0  45.0  10.0   0.0  60.0  10.0  ...  0.000007   \n",
              "3   5.0   2.0   2.0  87.0   0.0  45.0  10.0   0.0  53.0  10.0  ...  0.000007   \n",
              "4   5.0   2.0   2.0  95.0   0.0  45.0  10.0   0.0  51.0  10.0  ...  0.000007   \n",
              "\n",
              "       3245      3246      3247      3248      3249      3250      3251  \\\n",
              "0  0.000003  0.191408  0.000008  0.001210  0.000021  0.000003  0.000002   \n",
              "1  0.000003  0.188993  0.000032  0.000644  0.000041  0.000002  0.000003   \n",
              "2  0.000003  0.189576  0.000032  0.000692  0.000040  0.000003  0.000003   \n",
              "3  0.000003  0.189424  0.000034  0.000678  0.000043  0.000004  0.000003   \n",
              "4  0.000003  0.190030  0.000031  0.000674  0.000039  0.000003  0.000003   \n",
              "\n",
              "     3252      3253  \n",
              "0  0.1890  0.000006  \n",
              "1  0.1850  0.000029  \n",
              "2  0.1878  0.000030  \n",
              "3  0.1880  0.000031  \n",
              "4  0.1870  0.000029  \n",
              "\n",
              "[5 rows x 3254 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b0b8f28-2f62-4e50-8046-887ab92f1715\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>3244</th>\n",
              "      <th>3245</th>\n",
              "      <th>3246</th>\n",
              "      <th>3247</th>\n",
              "      <th>3248</th>\n",
              "      <th>3249</th>\n",
              "      <th>3250</th>\n",
              "      <th>3251</th>\n",
              "      <th>3252</th>\n",
              "      <th>3253</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.191408</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.001210</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.1890</td>\n",
              "      <td>0.000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.188993</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.1850</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.189576</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.1878</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.189424</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.1880</td>\n",
              "      <td>0.000031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.190030</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000674</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3254 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b0b8f28-2f62-4e50-8046-887ab92f1715')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b0b8f28-2f62-4e50-8046-887ab92f1715 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b0b8f28-2f62-4e50-8046-887ab92f1715');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "qe6GM0kbDNjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance\n",
        "- Feature Importance는 학습된 모델에서 주로 사용된 컬럼들을 나타내기 때문에, 학습에 도움이 되지 않은 컬럼을 지워준다고 해도 test predict에 영향력이 적다.\n",
        "- 줄어든 컬럼으로 학습 방식이 바뀌고, overfit을 완화하여 더 나은 결과를 유도할 수 있다."
      ],
      "metadata": {
        "id": "7EvNzaUO0psa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "P1UH0mOXFYUJ",
        "outputId": "7e6fdb2b-45be-4593-c305-7d25d3e6628c"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             LINE  PRODUCT_CODE         X_1         X_2    X_3         X_4  \\\n",
              "count  535.000000    535.000000  489.000000  489.000000  489.0  489.000000   \n",
              "mean     4.351402      1.824299    2.593047   94.670757    0.0   45.004090   \n",
              "std      0.907662      0.563370    9.967778    4.162181    0.0    0.063887   \n",
              "min      0.000000      0.000000    1.000000   87.000000    0.0   45.000000   \n",
              "25%      4.000000      2.000000    1.000000   91.000000    0.0   45.000000   \n",
              "50%      5.000000      2.000000    2.000000   95.000000    0.0   45.000000   \n",
              "75%      5.000000      2.000000    2.000000   97.000000    0.0   45.000000   \n",
              "max      5.000000      2.000000  158.000000  102.000000    0.0   46.000000   \n",
              "\n",
              "              X_5    X_6         X_7         X_8  ...      X_3317  \\\n",
              "count  489.000000  489.0  489.000000  489.000000  ...  153.000000   \n",
              "mean    10.269939    0.0   48.572597   10.002045  ...    0.000007   \n",
              "std      0.444382    0.0    3.437877    0.045222  ...    0.000001   \n",
              "min     10.000000    0.0   45.000000   10.000000  ...    0.000005   \n",
              "25%     10.000000    0.0   45.000000   10.000000  ...    0.000007   \n",
              "50%     10.000000    0.0   50.000000   10.000000  ...    0.000007   \n",
              "75%     11.000000    0.0   51.000000   10.000000  ...    0.000008   \n",
              "max     11.000000    0.0   64.000000   11.000000  ...    0.000012   \n",
              "\n",
              "             X_3318      X_3319      X_3320      X_3321      X_3322  \\\n",
              "count  1.530000e+02  153.000000  153.000000  153.000000  153.000000   \n",
              "mean   3.678431e-06    0.190252    0.000022    0.000940    0.000033   \n",
              "std    6.711068e-07    0.000804    0.000011    0.000284    0.000010   \n",
              "min    2.490000e-06    0.188201    0.000007    0.000642    0.000019   \n",
              "25%    3.260000e-06    0.189574    0.000010    0.000670    0.000023   \n",
              "50%    3.430000e-06    0.190208    0.000031    0.000721    0.000039   \n",
              "75%    4.000000e-06    0.190872    0.000032    0.001230    0.000042   \n",
              "max    6.530000e-06    0.192250    0.000036    0.001320    0.000049   \n",
              "\n",
              "           X_3323        X_3324      X_3325      X_3326  \n",
              "count  153.000000  1.530000e+02  153.000000  153.000000  \n",
              "mean     0.000003  2.251758e-06    0.188418    0.000019  \n",
              "std      0.000001  6.591602e-07    0.001537    0.000012  \n",
              "min      0.000002  6.470000e-07    0.185000    0.000003  \n",
              "25%      0.000003  1.680000e-06    0.187000    0.000006  \n",
              "50%      0.000003  2.520000e-06    0.189000    0.000028  \n",
              "75%      0.000004  2.780000e-06    0.190000    0.000030  \n",
              "max      0.000007  3.550000e-06    0.191000    0.000034  \n",
              "\n",
              "[8 rows x 3328 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5da51514-62f7-446a-9549-0b38461fe5d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_6</th>\n",
              "      <th>X_7</th>\n",
              "      <th>X_8</th>\n",
              "      <th>...</th>\n",
              "      <th>X_3317</th>\n",
              "      <th>X_3318</th>\n",
              "      <th>X_3319</th>\n",
              "      <th>X_3320</th>\n",
              "      <th>X_3321</th>\n",
              "      <th>X_3322</th>\n",
              "      <th>X_3323</th>\n",
              "      <th>X_3324</th>\n",
              "      <th>X_3325</th>\n",
              "      <th>X_3326</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>535.000000</td>\n",
              "      <td>535.000000</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>489.0</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>489.0</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>489.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>1.530000e+02</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>1.530000e+02</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.351402</td>\n",
              "      <td>1.824299</td>\n",
              "      <td>2.593047</td>\n",
              "      <td>94.670757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.004090</td>\n",
              "      <td>10.269939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.572597</td>\n",
              "      <td>10.002045</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.678431e-06</td>\n",
              "      <td>0.190252</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000940</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>2.251758e-06</td>\n",
              "      <td>0.188418</td>\n",
              "      <td>0.000019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.907662</td>\n",
              "      <td>0.563370</td>\n",
              "      <td>9.967778</td>\n",
              "      <td>4.162181</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063887</td>\n",
              "      <td>0.444382</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.437877</td>\n",
              "      <td>0.045222</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>6.711068e-07</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>6.591602e-07</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>2.490000e-06</td>\n",
              "      <td>0.188201</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>6.470000e-07</td>\n",
              "      <td>0.185000</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.260000e-06</td>\n",
              "      <td>0.189574</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.680000e-06</td>\n",
              "      <td>0.187000</td>\n",
              "      <td>0.000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.430000e-06</td>\n",
              "      <td>0.190208</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>2.520000e-06</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>4.000000e-06</td>\n",
              "      <td>0.190872</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.001230</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>2.780000e-06</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>6.530000e-06</td>\n",
              "      <td>0.192250</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.001320</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.550000e-06</td>\n",
              "      <td>0.191000</td>\n",
              "      <td>0.000034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 3328 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5da51514-62f7-446a-9549-0b38461fe5d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5da51514-62f7-446a-9549-0b38461fe5d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5da51514-62f7-446a-9549-0b38461fe5d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcY4Grz10l6h"
      },
      "outputs": [],
      "source": [
        "feat_list = []\n",
        "for _ in range(5):\n",
        "    clf = catboost.CatBoostClassifier(verbose=0, thread_count=5) # task_type='GPU'\n",
        "    clf.fit(train_x, train_y, \n",
        "            # early_stopping_rounds=100, \n",
        "            # cat_features=['PRODUCT_CODE', 'LINE']\n",
        "            )\n",
        "\n",
        "    feat_list.append(clf.feature_importances_)\n",
        "\n",
        "feat_list = np.array(feat_list)\n",
        "feat_max = np.array([max(feat_list[:, i]) for i in range(len(feat_list[0]))])    \n",
        "feature_imp = pd.Series(feat_max, index=train_x.columns).sort_values(ascending=False)[:20].sort_values()\n",
        "train_x = train_x[train_x.columns[feat_max>0.5]]  \n",
        "# train_x.columns = train_x.columns.to_list()\n",
        "test = test[train_x.columns]  \n",
        "\n",
        "# Visualization\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 15)\n",
        "plt.barh(feature_imp.index, feature_imp)\n",
        "plt.title('Feature_importance')\n",
        "plt.show()     \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzAyS6fr0l-M"
      },
      "outputs": [],
      "source": [
        "# train_x = train_x[feat_max]\n",
        "# test = test[feat_max]\n",
        "\n",
        "# # 영향력이 있는 모든 컬럼 출력\n",
        "# for c in train_x.columns:\n",
        "#     print(f'\"{c}\"', end=', ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "L6ufAtL1Te2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FfM7sKv0mCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa36785-0df4-4334-e31a-b1f2657cc225"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    467\n",
              "0     36\n",
              "2     32\n",
              "Name: Y_Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "clf = catboost.CatBoostClassifier(verbose=0, thread_count=5)\n",
        "fitted = clf.fit(train_x, train_y)\n",
        "pred = clf.predict(test)\n",
        "submit['Y_Class'] = pred\n",
        "submit.Y_Class.value_counts()  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "clf = LGBMClassifier(verbose=0, thread_count=5)\n",
        "fitted = clf.fit(train_x, train_y)\n",
        "preds = clf.predict(test_x)   \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YABid0Cyi5mf",
        "outputId": "d046ef3a-b92b-4917-9d7a-95eb4595f528"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032790 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(preds)\n",
        "pred.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unFrOduk6CHp",
        "outputId": "293524ce-1746-49bb-eee7-00876a8e5d74"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    420\n",
              "2     71\n",
              "0     44\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "Vm8q0p4Hyzg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de41d9bd-783d-4cc5-e965-262d0cef24dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.686213 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Learning rate set to 0.079629\n",
            "0:\tlearn: 1.0458323\ttotal: 523ms\tremaining: 8m 42s\n",
            "1:\tlearn: 1.0044632\ttotal: 905ms\tremaining: 7m 31s\n",
            "2:\tlearn: 0.9697559\ttotal: 1.28s\tremaining: 7m 5s\n",
            "3:\tlearn: 0.9386880\ttotal: 1.66s\tremaining: 6m 53s\n",
            "4:\tlearn: 0.9112284\ttotal: 2.03s\tremaining: 6m 43s\n",
            "5:\tlearn: 0.8878815\ttotal: 2.4s\tremaining: 6m 38s\n",
            "6:\tlearn: 0.8674621\ttotal: 2.78s\tremaining: 6m 34s\n",
            "7:\tlearn: 0.8510101\ttotal: 3.14s\tremaining: 6m 29s\n",
            "8:\tlearn: 0.8338051\ttotal: 3.53s\tremaining: 6m 28s\n",
            "9:\tlearn: 0.8202849\ttotal: 4.27s\tremaining: 7m 2s\n",
            "10:\tlearn: 0.8074364\ttotal: 4.97s\tremaining: 7m 27s\n",
            "11:\tlearn: 0.7964305\ttotal: 5.46s\tremaining: 7m 29s\n",
            "12:\tlearn: 0.7864231\ttotal: 5.83s\tremaining: 7m 22s\n",
            "13:\tlearn: 0.7760611\ttotal: 6.2s\tremaining: 7m 16s\n",
            "14:\tlearn: 0.7677060\ttotal: 6.58s\tremaining: 7m 11s\n",
            "15:\tlearn: 0.7582945\ttotal: 6.94s\tremaining: 7m 7s\n",
            "16:\tlearn: 0.7509240\ttotal: 7.31s\tremaining: 7m 2s\n",
            "17:\tlearn: 0.7433043\ttotal: 7.69s\tremaining: 6m 59s\n",
            "18:\tlearn: 0.7363080\ttotal: 8.07s\tremaining: 6m 56s\n",
            "19:\tlearn: 0.7301680\ttotal: 8.45s\tremaining: 6m 54s\n",
            "20:\tlearn: 0.7240834\ttotal: 8.85s\tremaining: 6m 52s\n",
            "21:\tlearn: 0.7189606\ttotal: 9.2s\tremaining: 6m 48s\n",
            "22:\tlearn: 0.7144503\ttotal: 9.59s\tremaining: 6m 47s\n",
            "23:\tlearn: 0.7070039\ttotal: 9.96s\tremaining: 6m 45s\n",
            "24:\tlearn: 0.7036250\ttotal: 10.3s\tremaining: 6m 43s\n",
            "25:\tlearn: 0.7001442\ttotal: 10.7s\tremaining: 6m 40s\n",
            "26:\tlearn: 0.6971564\ttotal: 11.1s\tremaining: 6m 38s\n",
            "27:\tlearn: 0.6922072\ttotal: 11.4s\tremaining: 6m 37s\n",
            "28:\tlearn: 0.6895259\ttotal: 11.8s\tremaining: 6m 35s\n",
            "29:\tlearn: 0.6851329\ttotal: 12.2s\tremaining: 6m 34s\n",
            "30:\tlearn: 0.6826104\ttotal: 12.6s\tremaining: 6m 32s\n",
            "31:\tlearn: 0.6780160\ttotal: 13s\tremaining: 6m 31s\n",
            "32:\tlearn: 0.6750630\ttotal: 13.3s\tremaining: 6m 29s\n",
            "33:\tlearn: 0.6711284\ttotal: 13.7s\tremaining: 6m 28s\n",
            "34:\tlearn: 0.6678941\ttotal: 14.1s\tremaining: 6m 27s\n",
            "35:\tlearn: 0.6659392\ttotal: 14.4s\tremaining: 6m 26s\n",
            "36:\tlearn: 0.6620659\ttotal: 14.8s\tremaining: 6m 24s\n",
            "37:\tlearn: 0.6590176\ttotal: 15.2s\tremaining: 6m 23s\n",
            "38:\tlearn: 0.6565227\ttotal: 15.8s\tremaining: 6m 30s\n",
            "39:\tlearn: 0.6523980\ttotal: 16.6s\tremaining: 6m 37s\n",
            "40:\tlearn: 0.6496519\ttotal: 17.1s\tremaining: 6m 41s\n",
            "41:\tlearn: 0.6469411\ttotal: 17.5s\tremaining: 6m 39s\n",
            "42:\tlearn: 0.6419656\ttotal: 17.9s\tremaining: 6m 38s\n",
            "43:\tlearn: 0.6398265\ttotal: 18.3s\tremaining: 6m 37s\n",
            "44:\tlearn: 0.6370281\ttotal: 18.6s\tremaining: 6m 35s\n",
            "45:\tlearn: 0.6350089\ttotal: 19s\tremaining: 6m 34s\n",
            "46:\tlearn: 0.6316365\ttotal: 19.4s\tremaining: 6m 33s\n",
            "47:\tlearn: 0.6307076\ttotal: 19.8s\tremaining: 6m 32s\n",
            "48:\tlearn: 0.6288467\ttotal: 20.1s\tremaining: 6m 30s\n",
            "49:\tlearn: 0.6268298\ttotal: 20.5s\tremaining: 6m 29s\n",
            "50:\tlearn: 0.6243883\ttotal: 20.9s\tremaining: 6m 28s\n",
            "51:\tlearn: 0.6225779\ttotal: 21.3s\tremaining: 6m 27s\n",
            "52:\tlearn: 0.6197189\ttotal: 21.6s\tremaining: 6m 26s\n",
            "53:\tlearn: 0.6178082\ttotal: 22s\tremaining: 6m 24s\n",
            "54:\tlearn: 0.6162859\ttotal: 22.3s\tremaining: 6m 23s\n",
            "55:\tlearn: 0.6148732\ttotal: 22.7s\tremaining: 6m 22s\n",
            "56:\tlearn: 0.6128489\ttotal: 23.1s\tremaining: 6m 21s\n",
            "57:\tlearn: 0.6119001\ttotal: 23.4s\tremaining: 6m 20s\n",
            "58:\tlearn: 0.6102302\ttotal: 23.8s\tremaining: 6m 19s\n",
            "59:\tlearn: 0.6084342\ttotal: 24.2s\tremaining: 6m 18s\n",
            "60:\tlearn: 0.6060000\ttotal: 24.5s\tremaining: 6m 17s\n",
            "61:\tlearn: 0.6037893\ttotal: 24.9s\tremaining: 6m 16s\n",
            "62:\tlearn: 0.6019433\ttotal: 25.3s\tremaining: 6m 16s\n",
            "63:\tlearn: 0.6006533\ttotal: 25.7s\tremaining: 6m 15s\n",
            "64:\tlearn: 0.5991996\ttotal: 26s\tremaining: 6m 14s\n",
            "65:\tlearn: 0.5972698\ttotal: 26.4s\tremaining: 6m 13s\n",
            "66:\tlearn: 0.5956964\ttotal: 26.8s\tremaining: 6m 12s\n",
            "67:\tlearn: 0.5942327\ttotal: 27.2s\tremaining: 6m 13s\n",
            "68:\tlearn: 0.5928506\ttotal: 27.9s\tremaining: 6m 16s\n",
            "69:\tlearn: 0.5920971\ttotal: 28.6s\tremaining: 6m 19s\n",
            "70:\tlearn: 0.5896983\ttotal: 29.1s\tremaining: 6m 20s\n",
            "71:\tlearn: 0.5869273\ttotal: 29.5s\tremaining: 6m 20s\n",
            "72:\tlearn: 0.5844785\ttotal: 29.9s\tremaining: 6m 19s\n",
            "73:\tlearn: 0.5819975\ttotal: 30.3s\tremaining: 6m 18s\n",
            "74:\tlearn: 0.5805194\ttotal: 30.6s\tremaining: 6m 17s\n",
            "75:\tlearn: 0.5783895\ttotal: 31s\tremaining: 6m 17s\n",
            "76:\tlearn: 0.5767614\ttotal: 31.4s\tremaining: 6m 16s\n",
            "77:\tlearn: 0.5738644\ttotal: 31.8s\tremaining: 6m 15s\n",
            "78:\tlearn: 0.5717816\ttotal: 32.1s\tremaining: 6m 14s\n",
            "79:\tlearn: 0.5709341\ttotal: 32.5s\tremaining: 6m 14s\n",
            "80:\tlearn: 0.5690090\ttotal: 32.9s\tremaining: 6m 13s\n",
            "81:\tlearn: 0.5680572\ttotal: 33.3s\tremaining: 6m 12s\n",
            "82:\tlearn: 0.5665969\ttotal: 33.6s\tremaining: 6m 11s\n",
            "83:\tlearn: 0.5645310\ttotal: 34s\tremaining: 6m 10s\n",
            "84:\tlearn: 0.5616505\ttotal: 34.4s\tremaining: 6m 9s\n",
            "85:\tlearn: 0.5591278\ttotal: 34.7s\tremaining: 6m 9s\n",
            "86:\tlearn: 0.5581661\ttotal: 35.1s\tremaining: 6m 8s\n",
            "87:\tlearn: 0.5565617\ttotal: 35.5s\tremaining: 6m 7s\n",
            "88:\tlearn: 0.5545193\ttotal: 35.9s\tremaining: 6m 6s\n",
            "89:\tlearn: 0.5529654\ttotal: 36.2s\tremaining: 6m 6s\n",
            "90:\tlearn: 0.5507085\ttotal: 36.6s\tremaining: 6m 5s\n",
            "91:\tlearn: 0.5489755\ttotal: 37s\tremaining: 6m 5s\n",
            "92:\tlearn: 0.5479506\ttotal: 37.4s\tremaining: 6m 4s\n",
            "93:\tlearn: 0.5469470\ttotal: 37.7s\tremaining: 6m 3s\n",
            "94:\tlearn: 0.5434579\ttotal: 38.1s\tremaining: 6m 3s\n",
            "95:\tlearn: 0.5425017\ttotal: 38.5s\tremaining: 6m 2s\n",
            "96:\tlearn: 0.5409484\ttotal: 38.8s\tremaining: 6m 1s\n",
            "97:\tlearn: 0.5394656\ttotal: 39.5s\tremaining: 6m 3s\n",
            "98:\tlearn: 0.5368468\ttotal: 40.2s\tremaining: 6m 5s\n",
            "99:\tlearn: 0.5358215\ttotal: 40.8s\tremaining: 6m 6s\n",
            "100:\tlearn: 0.5341725\ttotal: 41.1s\tremaining: 6m 6s\n",
            "101:\tlearn: 0.5312688\ttotal: 41.5s\tremaining: 6m 5s\n",
            "102:\tlearn: 0.5290210\ttotal: 41.9s\tremaining: 6m 4s\n",
            "103:\tlearn: 0.5272643\ttotal: 42.3s\tremaining: 6m 4s\n",
            "104:\tlearn: 0.5255179\ttotal: 42.6s\tremaining: 6m 3s\n",
            "105:\tlearn: 0.5233689\ttotal: 43s\tremaining: 6m 2s\n",
            "106:\tlearn: 0.5224786\ttotal: 43.4s\tremaining: 6m 1s\n",
            "107:\tlearn: 0.5213891\ttotal: 43.8s\tremaining: 6m 1s\n",
            "108:\tlearn: 0.5192798\ttotal: 44.1s\tremaining: 6m\n",
            "109:\tlearn: 0.5183588\ttotal: 44.5s\tremaining: 6m\n",
            "110:\tlearn: 0.5168572\ttotal: 44.9s\tremaining: 5m 59s\n",
            "111:\tlearn: 0.5145590\ttotal: 45.3s\tremaining: 5m 58s\n",
            "112:\tlearn: 0.5127029\ttotal: 45.6s\tremaining: 5m 58s\n",
            "113:\tlearn: 0.5094716\ttotal: 46s\tremaining: 5m 57s\n",
            "114:\tlearn: 0.5083385\ttotal: 46.4s\tremaining: 5m 56s\n",
            "115:\tlearn: 0.5070816\ttotal: 46.8s\tremaining: 5m 56s\n",
            "116:\tlearn: 0.5047312\ttotal: 47.1s\tremaining: 5m 55s\n",
            "117:\tlearn: 0.5025445\ttotal: 47.5s\tremaining: 5m 55s\n",
            "118:\tlearn: 0.5006737\ttotal: 47.9s\tremaining: 5m 54s\n",
            "119:\tlearn: 0.4998840\ttotal: 48.3s\tremaining: 5m 53s\n",
            "120:\tlearn: 0.4983330\ttotal: 48.6s\tremaining: 5m 53s\n",
            "121:\tlearn: 0.4960229\ttotal: 49s\tremaining: 5m 52s\n",
            "122:\tlearn: 0.4946902\ttotal: 49.4s\tremaining: 5m 52s\n",
            "123:\tlearn: 0.4940621\ttotal: 49.7s\tremaining: 5m 51s\n",
            "124:\tlearn: 0.4932236\ttotal: 50.1s\tremaining: 5m 50s\n",
            "125:\tlearn: 0.4922258\ttotal: 50.5s\tremaining: 5m 50s\n",
            "126:\tlearn: 0.4905631\ttotal: 50.9s\tremaining: 5m 50s\n",
            "127:\tlearn: 0.4897223\ttotal: 51.6s\tremaining: 5m 51s\n",
            "128:\tlearn: 0.4880562\ttotal: 52.3s\tremaining: 5m 53s\n",
            "129:\tlearn: 0.4863590\ttotal: 52.8s\tremaining: 5m 53s\n",
            "130:\tlearn: 0.4846137\ttotal: 53.1s\tremaining: 5m 52s\n",
            "131:\tlearn: 0.4831367\ttotal: 53.5s\tremaining: 5m 51s\n",
            "132:\tlearn: 0.4819780\ttotal: 53.9s\tremaining: 5m 51s\n",
            "133:\tlearn: 0.4812606\ttotal: 54.3s\tremaining: 5m 50s\n",
            "134:\tlearn: 0.4786418\ttotal: 54.6s\tremaining: 5m 50s\n",
            "135:\tlearn: 0.4767853\ttotal: 55s\tremaining: 5m 49s\n",
            "136:\tlearn: 0.4746346\ttotal: 55.4s\tremaining: 5m 48s\n",
            "137:\tlearn: 0.4732787\ttotal: 55.8s\tremaining: 5m 48s\n",
            "138:\tlearn: 0.4720109\ttotal: 56.1s\tremaining: 5m 47s\n",
            "139:\tlearn: 0.4702309\ttotal: 56.5s\tremaining: 5m 47s\n",
            "140:\tlearn: 0.4688599\ttotal: 56.9s\tremaining: 5m 46s\n",
            "141:\tlearn: 0.4668390\ttotal: 57.3s\tremaining: 5m 46s\n",
            "142:\tlearn: 0.4649606\ttotal: 57.6s\tremaining: 5m 45s\n",
            "143:\tlearn: 0.4643526\ttotal: 58s\tremaining: 5m 44s\n",
            "144:\tlearn: 0.4634335\ttotal: 58.4s\tremaining: 5m 44s\n",
            "145:\tlearn: 0.4619620\ttotal: 58.7s\tremaining: 5m 43s\n",
            "146:\tlearn: 0.4608344\ttotal: 59.1s\tremaining: 5m 43s\n",
            "147:\tlearn: 0.4591658\ttotal: 59.5s\tremaining: 5m 42s\n",
            "148:\tlearn: 0.4570096\ttotal: 59.9s\tremaining: 5m 41s\n",
            "149:\tlearn: 0.4559027\ttotal: 1m\tremaining: 5m 41s\n",
            "150:\tlearn: 0.4553930\ttotal: 1m\tremaining: 5m 40s\n",
            "151:\tlearn: 0.4528222\ttotal: 1m\tremaining: 5m 40s\n",
            "152:\tlearn: 0.4512260\ttotal: 1m 1s\tremaining: 5m 39s\n",
            "153:\tlearn: 0.4496797\ttotal: 1m 1s\tremaining: 5m 39s\n",
            "154:\tlearn: 0.4480063\ttotal: 1m 2s\tremaining: 5m 38s\n",
            "155:\tlearn: 0.4466543\ttotal: 1m 2s\tremaining: 5m 38s\n",
            "156:\tlearn: 0.4459358\ttotal: 1m 3s\tremaining: 5m 39s\n",
            "157:\tlearn: 0.4449009\ttotal: 1m 3s\tremaining: 5m 40s\n",
            "158:\tlearn: 0.4432890\ttotal: 1m 4s\tremaining: 5m 40s\n",
            "159:\tlearn: 0.4417521\ttotal: 1m 4s\tremaining: 5m 40s\n",
            "160:\tlearn: 0.4410646\ttotal: 1m 5s\tremaining: 5m 39s\n",
            "161:\tlearn: 0.4395317\ttotal: 1m 5s\tremaining: 5m 39s\n",
            "162:\tlearn: 0.4386195\ttotal: 1m 6s\tremaining: 5m 40s\n",
            "163:\tlearn: 0.4372102\ttotal: 1m 7s\tremaining: 5m 41s\n",
            "164:\tlearn: 0.4351094\ttotal: 1m 7s\tremaining: 5m 41s\n",
            "165:\tlearn: 0.4343682\ttotal: 1m 7s\tremaining: 5m 41s\n",
            "166:\tlearn: 0.4332781\ttotal: 1m 8s\tremaining: 5m 40s\n",
            "167:\tlearn: 0.4324710\ttotal: 1m 8s\tremaining: 5m 39s\n",
            "168:\tlearn: 0.4313539\ttotal: 1m 8s\tremaining: 5m 39s\n",
            "169:\tlearn: 0.4297772\ttotal: 1m 9s\tremaining: 5m 38s\n",
            "170:\tlearn: 0.4280286\ttotal: 1m 9s\tremaining: 5m 38s\n",
            "171:\tlearn: 0.4262945\ttotal: 1m 10s\tremaining: 5m 37s\n",
            "172:\tlearn: 0.4251528\ttotal: 1m 10s\tremaining: 5m 37s\n",
            "173:\tlearn: 0.4244215\ttotal: 1m 10s\tremaining: 5m 36s\n",
            "174:\tlearn: 0.4236055\ttotal: 1m 11s\tremaining: 5m 36s\n",
            "175:\tlearn: 0.4222515\ttotal: 1m 11s\tremaining: 5m 35s\n",
            "176:\tlearn: 0.4214748\ttotal: 1m 12s\tremaining: 5m 34s\n",
            "177:\tlearn: 0.4206394\ttotal: 1m 12s\tremaining: 5m 34s\n",
            "178:\tlearn: 0.4199613\ttotal: 1m 12s\tremaining: 5m 33s\n",
            "179:\tlearn: 0.4183765\ttotal: 1m 13s\tremaining: 5m 33s\n",
            "180:\tlearn: 0.4162650\ttotal: 1m 13s\tremaining: 5m 32s\n",
            "181:\tlearn: 0.4152721\ttotal: 1m 13s\tremaining: 5m 32s\n",
            "182:\tlearn: 0.4145730\ttotal: 1m 14s\tremaining: 5m 31s\n",
            "183:\tlearn: 0.4136390\ttotal: 1m 14s\tremaining: 5m 32s\n",
            "184:\tlearn: 0.4126394\ttotal: 1m 15s\tremaining: 5m 32s\n",
            "185:\tlearn: 0.4119063\ttotal: 1m 16s\tremaining: 5m 33s\n",
            "186:\tlearn: 0.4109343\ttotal: 1m 16s\tremaining: 5m 32s\n",
            "187:\tlearn: 0.4092390\ttotal: 1m 16s\tremaining: 5m 32s\n",
            "188:\tlearn: 0.4085104\ttotal: 1m 17s\tremaining: 5m 31s\n",
            "189:\tlearn: 0.4076352\ttotal: 1m 17s\tremaining: 5m 31s\n",
            "190:\tlearn: 0.4063689\ttotal: 1m 18s\tremaining: 5m 30s\n",
            "191:\tlearn: 0.4057338\ttotal: 1m 18s\tremaining: 5m 30s\n",
            "192:\tlearn: 0.4050579\ttotal: 1m 18s\tremaining: 5m 29s\n",
            "193:\tlearn: 0.4037078\ttotal: 1m 19s\tremaining: 5m 28s\n",
            "194:\tlearn: 0.4025125\ttotal: 1m 19s\tremaining: 5m 28s\n",
            "195:\tlearn: 0.4011656\ttotal: 1m 19s\tremaining: 5m 27s\n",
            "196:\tlearn: 0.4002888\ttotal: 1m 20s\tremaining: 5m 27s\n",
            "197:\tlearn: 0.3995271\ttotal: 1m 21s\tremaining: 5m 28s\n",
            "198:\tlearn: 0.3987568\ttotal: 1m 22s\tremaining: 5m 31s\n",
            "199:\tlearn: 0.3981337\ttotal: 1m 23s\tremaining: 5m 32s\n",
            "200:\tlearn: 0.3975650\ttotal: 1m 24s\tremaining: 5m 34s\n",
            "201:\tlearn: 0.3959026\ttotal: 1m 24s\tremaining: 5m 34s\n",
            "202:\tlearn: 0.3950163\ttotal: 1m 25s\tremaining: 5m 35s\n",
            "203:\tlearn: 0.3939149\ttotal: 1m 25s\tremaining: 5m 34s\n",
            "204:\tlearn: 0.3927720\ttotal: 1m 26s\tremaining: 5m 33s\n",
            "205:\tlearn: 0.3918229\ttotal: 1m 26s\tremaining: 5m 33s\n",
            "206:\tlearn: 0.3906657\ttotal: 1m 27s\tremaining: 5m 34s\n",
            "207:\tlearn: 0.3891893\ttotal: 1m 27s\tremaining: 5m 34s\n",
            "208:\tlearn: 0.3883173\ttotal: 1m 28s\tremaining: 5m 34s\n",
            "209:\tlearn: 0.3878939\ttotal: 1m 28s\tremaining: 5m 34s\n",
            "210:\tlearn: 0.3863259\ttotal: 1m 29s\tremaining: 5m 33s\n",
            "211:\tlearn: 0.3860460\ttotal: 1m 29s\tremaining: 5m 32s\n",
            "212:\tlearn: 0.3854998\ttotal: 1m 29s\tremaining: 5m 32s\n",
            "213:\tlearn: 0.3840789\ttotal: 1m 30s\tremaining: 5m 31s\n",
            "214:\tlearn: 0.3832675\ttotal: 1m 30s\tremaining: 5m 31s\n",
            "215:\tlearn: 0.3825203\ttotal: 1m 31s\tremaining: 5m 30s\n",
            "216:\tlearn: 0.3818234\ttotal: 1m 31s\tremaining: 5m 29s\n",
            "217:\tlearn: 0.3813898\ttotal: 1m 31s\tremaining: 5m 29s\n",
            "218:\tlearn: 0.3808593\ttotal: 1m 32s\tremaining: 5m 28s\n",
            "219:\tlearn: 0.3797139\ttotal: 1m 32s\tremaining: 5m 28s\n",
            "220:\tlearn: 0.3776976\ttotal: 1m 32s\tremaining: 5m 27s\n",
            "221:\tlearn: 0.3771524\ttotal: 1m 33s\tremaining: 5m 26s\n",
            "222:\tlearn: 0.3765504\ttotal: 1m 33s\tremaining: 5m 26s\n",
            "223:\tlearn: 0.3759698\ttotal: 1m 34s\tremaining: 5m 25s\n",
            "224:\tlearn: 0.3750861\ttotal: 1m 34s\tremaining: 5m 25s\n",
            "225:\tlearn: 0.3743048\ttotal: 1m 34s\tremaining: 5m 24s\n",
            "226:\tlearn: 0.3731273\ttotal: 1m 35s\tremaining: 5m 24s\n",
            "227:\tlearn: 0.3724807\ttotal: 1m 35s\tremaining: 5m 23s\n",
            "228:\tlearn: 0.3710110\ttotal: 1m 35s\tremaining: 5m 22s\n",
            "229:\tlearn: 0.3705628\ttotal: 1m 36s\tremaining: 5m 22s\n",
            "230:\tlearn: 0.3699859\ttotal: 1m 36s\tremaining: 5m 21s\n",
            "231:\tlearn: 0.3687180\ttotal: 1m 37s\tremaining: 5m 21s\n",
            "232:\tlearn: 0.3679559\ttotal: 1m 37s\tremaining: 5m 20s\n",
            "233:\tlearn: 0.3667633\ttotal: 1m 37s\tremaining: 5m 20s\n",
            "234:\tlearn: 0.3647911\ttotal: 1m 38s\tremaining: 5m 19s\n",
            "235:\tlearn: 0.3637130\ttotal: 1m 38s\tremaining: 5m 19s\n",
            "236:\tlearn: 0.3629036\ttotal: 1m 39s\tremaining: 5m 19s\n",
            "237:\tlearn: 0.3625823\ttotal: 1m 39s\tremaining: 5m 20s\n",
            "238:\tlearn: 0.3621229\ttotal: 1m 40s\tremaining: 5m 19s\n",
            "239:\tlearn: 0.3615554\ttotal: 1m 40s\tremaining: 5m 19s\n",
            "240:\tlearn: 0.3609317\ttotal: 1m 41s\tremaining: 5m 18s\n",
            "241:\tlearn: 0.3605364\ttotal: 1m 41s\tremaining: 5m 18s\n",
            "242:\tlearn: 0.3593630\ttotal: 1m 41s\tremaining: 5m 17s\n",
            "243:\tlearn: 0.3590185\ttotal: 1m 42s\tremaining: 5m 16s\n",
            "244:\tlearn: 0.3575746\ttotal: 1m 42s\tremaining: 5m 16s\n",
            "245:\tlearn: 0.3559761\ttotal: 1m 43s\tremaining: 5m 15s\n",
            "246:\tlearn: 0.3556470\ttotal: 1m 43s\tremaining: 5m 15s\n",
            "247:\tlearn: 0.3543256\ttotal: 1m 43s\tremaining: 5m 14s\n",
            "248:\tlearn: 0.3535594\ttotal: 1m 44s\tremaining: 5m 14s\n",
            "249:\tlearn: 0.3529491\ttotal: 1m 44s\tremaining: 5m 13s\n",
            "250:\tlearn: 0.3517930\ttotal: 1m 44s\tremaining: 5m 13s\n",
            "251:\tlearn: 0.3509957\ttotal: 1m 45s\tremaining: 5m 12s\n",
            "252:\tlearn: 0.3498626\ttotal: 1m 45s\tremaining: 5m 12s\n",
            "253:\tlearn: 0.3492606\ttotal: 1m 46s\tremaining: 5m 11s\n",
            "254:\tlearn: 0.3485044\ttotal: 1m 46s\tremaining: 5m 10s\n",
            "255:\tlearn: 0.3471518\ttotal: 1m 46s\tremaining: 5m 10s\n",
            "256:\tlearn: 0.3463567\ttotal: 1m 47s\tremaining: 5m 9s\n",
            "257:\tlearn: 0.3457863\ttotal: 1m 47s\tremaining: 5m 9s\n",
            "258:\tlearn: 0.3448365\ttotal: 1m 47s\tremaining: 5m 8s\n",
            "259:\tlearn: 0.3444622\ttotal: 1m 48s\tremaining: 5m 8s\n",
            "260:\tlearn: 0.3438436\ttotal: 1m 48s\tremaining: 5m 7s\n",
            "261:\tlearn: 0.3431226\ttotal: 1m 49s\tremaining: 5m 7s\n",
            "262:\tlearn: 0.3428448\ttotal: 1m 49s\tremaining: 5m 6s\n",
            "263:\tlearn: 0.3419583\ttotal: 1m 49s\tremaining: 5m 5s\n",
            "264:\tlearn: 0.3411750\ttotal: 1m 50s\tremaining: 5m 5s\n",
            "265:\tlearn: 0.3404855\ttotal: 1m 50s\tremaining: 5m 5s\n",
            "266:\tlearn: 0.3402005\ttotal: 1m 51s\tremaining: 5m 5s\n",
            "267:\tlearn: 0.3397428\ttotal: 1m 51s\tremaining: 5m 5s\n",
            "268:\tlearn: 0.3395721\ttotal: 1m 52s\tremaining: 5m 5s\n",
            "269:\tlearn: 0.3390252\ttotal: 1m 52s\tremaining: 5m 4s\n",
            "270:\tlearn: 0.3386768\ttotal: 1m 53s\tremaining: 5m 4s\n",
            "271:\tlearn: 0.3380917\ttotal: 1m 53s\tremaining: 5m 3s\n",
            "272:\tlearn: 0.3374261\ttotal: 1m 53s\tremaining: 5m 3s\n",
            "273:\tlearn: 0.3367234\ttotal: 1m 54s\tremaining: 5m 2s\n",
            "274:\tlearn: 0.3359590\ttotal: 1m 54s\tremaining: 5m 2s\n",
            "275:\tlearn: 0.3352940\ttotal: 1m 54s\tremaining: 5m 1s\n",
            "276:\tlearn: 0.3346755\ttotal: 1m 55s\tremaining: 5m\n",
            "277:\tlearn: 0.3342351\ttotal: 1m 55s\tremaining: 5m\n",
            "278:\tlearn: 0.3339035\ttotal: 1m 56s\tremaining: 4m 59s\n",
            "279:\tlearn: 0.3329374\ttotal: 1m 56s\tremaining: 4m 59s\n",
            "280:\tlearn: 0.3325549\ttotal: 1m 56s\tremaining: 4m 58s\n",
            "281:\tlearn: 0.3316874\ttotal: 1m 57s\tremaining: 4m 58s\n",
            "282:\tlearn: 0.3307711\ttotal: 1m 57s\tremaining: 4m 57s\n",
            "283:\tlearn: 0.3302715\ttotal: 1m 57s\tremaining: 4m 57s\n",
            "284:\tlearn: 0.3293446\ttotal: 1m 58s\tremaining: 4m 56s\n",
            "285:\tlearn: 0.3284776\ttotal: 1m 58s\tremaining: 4m 56s\n",
            "286:\tlearn: 0.3277413\ttotal: 1m 59s\tremaining: 4m 55s\n",
            "287:\tlearn: 0.3270764\ttotal: 1m 59s\tremaining: 4m 55s\n",
            "288:\tlearn: 0.3267851\ttotal: 1m 59s\tremaining: 4m 54s\n",
            "289:\tlearn: 0.3261036\ttotal: 2m\tremaining: 4m 54s\n",
            "290:\tlearn: 0.3254376\ttotal: 2m\tremaining: 4m 53s\n",
            "291:\tlearn: 0.3242549\ttotal: 2m\tremaining: 4m 53s\n",
            "292:\tlearn: 0.3239503\ttotal: 2m 1s\tremaining: 4m 52s\n",
            "293:\tlearn: 0.3238115\ttotal: 2m 1s\tremaining: 4m 51s\n",
            "294:\tlearn: 0.3230141\ttotal: 2m 1s\tremaining: 4m 51s\n",
            "295:\tlearn: 0.3226530\ttotal: 2m 2s\tremaining: 4m 51s\n",
            "296:\tlearn: 0.3218084\ttotal: 2m 3s\tremaining: 4m 51s\n",
            "297:\tlearn: 0.3211074\ttotal: 2m 3s\tremaining: 4m 51s\n",
            "298:\tlearn: 0.3208807\ttotal: 2m 4s\tremaining: 4m 51s\n",
            "299:\tlearn: 0.3200656\ttotal: 2m 4s\tremaining: 4m 50s\n",
            "300:\tlearn: 0.3194381\ttotal: 2m 4s\tremaining: 4m 50s\n",
            "301:\tlearn: 0.3185852\ttotal: 2m 5s\tremaining: 4m 49s\n",
            "302:\tlearn: 0.3179920\ttotal: 2m 5s\tremaining: 4m 49s\n",
            "303:\tlearn: 0.3173768\ttotal: 2m 6s\tremaining: 4m 48s\n",
            "304:\tlearn: 0.3166490\ttotal: 2m 6s\tremaining: 4m 48s\n",
            "305:\tlearn: 0.3158185\ttotal: 2m 6s\tremaining: 4m 47s\n",
            "306:\tlearn: 0.3154925\ttotal: 2m 7s\tremaining: 4m 47s\n",
            "307:\tlearn: 0.3145144\ttotal: 2m 7s\tremaining: 4m 46s\n",
            "308:\tlearn: 0.3141724\ttotal: 2m 7s\tremaining: 4m 45s\n",
            "309:\tlearn: 0.3136192\ttotal: 2m 8s\tremaining: 4m 45s\n",
            "310:\tlearn: 0.3129178\ttotal: 2m 8s\tremaining: 4m 44s\n",
            "311:\tlearn: 0.3123201\ttotal: 2m 8s\tremaining: 4m 44s\n",
            "312:\tlearn: 0.3119265\ttotal: 2m 9s\tremaining: 4m 43s\n",
            "313:\tlearn: 0.3116949\ttotal: 2m 9s\tremaining: 4m 43s\n",
            "314:\tlearn: 0.3111642\ttotal: 2m 10s\tremaining: 4m 42s\n",
            "315:\tlearn: 0.3106855\ttotal: 2m 10s\tremaining: 4m 42s\n",
            "316:\tlearn: 0.3102486\ttotal: 2m 10s\tremaining: 4m 41s\n",
            "317:\tlearn: 0.3089136\ttotal: 2m 11s\tremaining: 4m 41s\n",
            "318:\tlearn: 0.3087107\ttotal: 2m 11s\tremaining: 4m 40s\n",
            "319:\tlearn: 0.3080695\ttotal: 2m 11s\tremaining: 4m 40s\n",
            "320:\tlearn: 0.3068768\ttotal: 2m 12s\tremaining: 4m 39s\n",
            "321:\tlearn: 0.3056212\ttotal: 2m 12s\tremaining: 4m 39s\n",
            "322:\tlearn: 0.3046446\ttotal: 2m 13s\tremaining: 4m 38s\n",
            "323:\tlearn: 0.3042378\ttotal: 2m 13s\tremaining: 4m 38s\n",
            "324:\tlearn: 0.3035307\ttotal: 2m 13s\tremaining: 4m 37s\n",
            "325:\tlearn: 0.3027868\ttotal: 2m 14s\tremaining: 4m 37s\n",
            "326:\tlearn: 0.3019683\ttotal: 2m 15s\tremaining: 4m 37s\n",
            "327:\tlearn: 0.3005902\ttotal: 2m 15s\tremaining: 4m 37s\n",
            "328:\tlearn: 0.2999495\ttotal: 2m 16s\tremaining: 4m 37s\n",
            "329:\tlearn: 0.2993696\ttotal: 2m 16s\tremaining: 4m 37s\n",
            "330:\tlearn: 0.2986549\ttotal: 2m 16s\tremaining: 4m 36s\n",
            "331:\tlearn: 0.2976452\ttotal: 2m 17s\tremaining: 4m 36s\n",
            "332:\tlearn: 0.2972886\ttotal: 2m 17s\tremaining: 4m 35s\n",
            "333:\tlearn: 0.2964323\ttotal: 2m 18s\tremaining: 4m 35s\n",
            "334:\tlearn: 0.2959891\ttotal: 2m 18s\tremaining: 4m 34s\n",
            "335:\tlearn: 0.2953122\ttotal: 2m 18s\tremaining: 4m 34s\n",
            "336:\tlearn: 0.2950414\ttotal: 2m 19s\tremaining: 4m 33s\n",
            "337:\tlearn: 0.2947870\ttotal: 2m 19s\tremaining: 4m 33s\n",
            "338:\tlearn: 0.2943449\ttotal: 2m 19s\tremaining: 4m 32s\n",
            "339:\tlearn: 0.2940441\ttotal: 2m 20s\tremaining: 4m 32s\n",
            "340:\tlearn: 0.2935246\ttotal: 2m 20s\tremaining: 4m 31s\n",
            "341:\tlearn: 0.2926885\ttotal: 2m 21s\tremaining: 4m 31s\n",
            "342:\tlearn: 0.2917846\ttotal: 2m 21s\tremaining: 4m 30s\n",
            "343:\tlearn: 0.2912417\ttotal: 2m 21s\tremaining: 4m 30s\n",
            "344:\tlearn: 0.2908786\ttotal: 2m 22s\tremaining: 4m 29s\n",
            "345:\tlearn: 0.2899495\ttotal: 2m 22s\tremaining: 4m 29s\n",
            "346:\tlearn: 0.2891208\ttotal: 2m 22s\tremaining: 4m 28s\n",
            "347:\tlearn: 0.2887555\ttotal: 2m 23s\tremaining: 4m 28s\n",
            "348:\tlearn: 0.2875212\ttotal: 2m 23s\tremaining: 4m 27s\n",
            "349:\tlearn: 0.2871701\ttotal: 2m 23s\tremaining: 4m 27s\n",
            "350:\tlearn: 0.2868732\ttotal: 2m 24s\tremaining: 4m 27s\n",
            "351:\tlearn: 0.2855656\ttotal: 2m 25s\tremaining: 4m 27s\n",
            "352:\tlearn: 0.2851064\ttotal: 2m 26s\tremaining: 4m 27s\n",
            "353:\tlearn: 0.2843420\ttotal: 2m 26s\tremaining: 4m 28s\n",
            "354:\tlearn: 0.2836844\ttotal: 2m 28s\tremaining: 4m 29s\n",
            "355:\tlearn: 0.2830668\ttotal: 2m 28s\tremaining: 4m 29s\n",
            "356:\tlearn: 0.2823774\ttotal: 2m 29s\tremaining: 4m 28s\n",
            "357:\tlearn: 0.2815280\ttotal: 2m 30s\tremaining: 4m 29s\n",
            "358:\tlearn: 0.2808509\ttotal: 2m 31s\tremaining: 4m 30s\n",
            "359:\tlearn: 0.2799442\ttotal: 2m 32s\tremaining: 4m 30s\n",
            "360:\tlearn: 0.2795190\ttotal: 2m 32s\tremaining: 4m 30s\n",
            "361:\tlearn: 0.2791065\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "362:\tlearn: 0.2786156\ttotal: 2m 34s\tremaining: 4m 30s\n",
            "363:\tlearn: 0.2781250\ttotal: 2m 34s\tremaining: 4m 30s\n",
            "364:\tlearn: 0.2777394\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "365:\tlearn: 0.2770477\ttotal: 2m 35s\tremaining: 4m 29s\n",
            "366:\tlearn: 0.2764753\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "367:\tlearn: 0.2756767\ttotal: 2m 36s\tremaining: 4m 28s\n",
            "368:\tlearn: 0.2752918\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "369:\tlearn: 0.2749916\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "370:\tlearn: 0.2745864\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "371:\tlearn: 0.2740340\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "372:\tlearn: 0.2730315\ttotal: 2m 37s\tremaining: 4m 25s\n",
            "373:\tlearn: 0.2726599\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "374:\tlearn: 0.2722582\ttotal: 2m 39s\tremaining: 4m 25s\n",
            "375:\tlearn: 0.2719135\ttotal: 2m 39s\tremaining: 4m 25s\n",
            "376:\tlearn: 0.2715954\ttotal: 2m 40s\tremaining: 4m 24s\n",
            "377:\tlearn: 0.2712114\ttotal: 2m 40s\tremaining: 4m 24s\n",
            "378:\tlearn: 0.2706510\ttotal: 2m 41s\tremaining: 4m 23s\n",
            "379:\tlearn: 0.2702023\ttotal: 2m 41s\tremaining: 4m 23s\n",
            "380:\tlearn: 0.2698626\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "381:\tlearn: 0.2692866\ttotal: 2m 42s\tremaining: 4m 22s\n",
            "382:\tlearn: 0.2690658\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "383:\tlearn: 0.2687402\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "384:\tlearn: 0.2683006\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "385:\tlearn: 0.2677680\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "386:\tlearn: 0.2672890\ttotal: 2m 43s\tremaining: 4m 19s\n",
            "387:\tlearn: 0.2668299\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "388:\tlearn: 0.2664575\ttotal: 2m 44s\tremaining: 4m 18s\n",
            "389:\tlearn: 0.2659468\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "390:\tlearn: 0.2657087\ttotal: 2m 45s\tremaining: 4m 17s\n",
            "391:\tlearn: 0.2653263\ttotal: 2m 45s\tremaining: 4m 17s\n",
            "392:\tlearn: 0.2650844\ttotal: 2m 46s\tremaining: 4m 16s\n",
            "393:\tlearn: 0.2647753\ttotal: 2m 46s\tremaining: 4m 16s\n",
            "394:\tlearn: 0.2646157\ttotal: 2m 46s\tremaining: 4m 15s\n",
            "395:\tlearn: 0.2638991\ttotal: 2m 47s\tremaining: 4m 15s\n",
            "396:\tlearn: 0.2635531\ttotal: 2m 47s\tremaining: 4m 14s\n",
            "397:\tlearn: 0.2630751\ttotal: 2m 48s\tremaining: 4m 14s\n",
            "398:\tlearn: 0.2626990\ttotal: 2m 48s\tremaining: 4m 13s\n",
            "399:\tlearn: 0.2621073\ttotal: 2m 48s\tremaining: 4m 13s\n",
            "400:\tlearn: 0.2618392\ttotal: 2m 49s\tremaining: 4m 12s\n",
            "401:\tlearn: 0.2613188\ttotal: 2m 49s\tremaining: 4m 12s\n",
            "402:\tlearn: 0.2609350\ttotal: 2m 49s\tremaining: 4m 11s\n",
            "403:\tlearn: 0.2602651\ttotal: 2m 50s\tremaining: 4m 11s\n",
            "404:\tlearn: 0.2601590\ttotal: 2m 51s\tremaining: 4m 11s\n",
            "405:\tlearn: 0.2596504\ttotal: 2m 51s\tremaining: 4m 11s\n",
            "406:\tlearn: 0.2585784\ttotal: 2m 52s\tremaining: 4m 10s\n",
            "407:\tlearn: 0.2581248\ttotal: 2m 52s\tremaining: 4m 10s\n",
            "408:\tlearn: 0.2576215\ttotal: 2m 52s\tremaining: 4m 9s\n",
            "409:\tlearn: 0.2570395\ttotal: 2m 53s\tremaining: 4m 9s\n",
            "410:\tlearn: 0.2562871\ttotal: 2m 53s\tremaining: 4m 8s\n",
            "411:\tlearn: 0.2559265\ttotal: 2m 54s\tremaining: 4m 8s\n",
            "412:\tlearn: 0.2555435\ttotal: 2m 54s\tremaining: 4m 7s\n",
            "413:\tlearn: 0.2552367\ttotal: 2m 54s\tremaining: 4m 7s\n",
            "414:\tlearn: 0.2551078\ttotal: 2m 55s\tremaining: 4m 6s\n",
            "415:\tlearn: 0.2544613\ttotal: 2m 55s\tremaining: 4m 6s\n",
            "416:\tlearn: 0.2537996\ttotal: 2m 55s\tremaining: 4m 5s\n",
            "417:\tlearn: 0.2533295\ttotal: 2m 56s\tremaining: 4m 5s\n",
            "418:\tlearn: 0.2531911\ttotal: 2m 56s\tremaining: 4m 4s\n",
            "419:\tlearn: 0.2527224\ttotal: 2m 57s\tremaining: 4m 4s\n",
            "420:\tlearn: 0.2525149\ttotal: 2m 57s\tremaining: 4m 3s\n",
            "421:\tlearn: 0.2517809\ttotal: 2m 57s\tremaining: 4m 3s\n",
            "422:\tlearn: 0.2515037\ttotal: 2m 58s\tremaining: 4m 2s\n",
            "423:\tlearn: 0.2513667\ttotal: 2m 58s\tremaining: 4m 2s\n",
            "424:\tlearn: 0.2510777\ttotal: 2m 58s\tremaining: 4m 1s\n",
            "425:\tlearn: 0.2507521\ttotal: 2m 59s\tremaining: 4m 1s\n",
            "426:\tlearn: 0.2505577\ttotal: 2m 59s\tremaining: 4m\n",
            "427:\tlearn: 0.2498635\ttotal: 2m 59s\tremaining: 4m\n",
            "428:\tlearn: 0.2493764\ttotal: 3m\tremaining: 4m\n",
            "429:\tlearn: 0.2486400\ttotal: 3m\tremaining: 3m 59s\n",
            "430:\tlearn: 0.2482489\ttotal: 3m 1s\tremaining: 3m 59s\n",
            "431:\tlearn: 0.2474236\ttotal: 3m 1s\tremaining: 3m 58s\n",
            "432:\tlearn: 0.2467516\ttotal: 3m 2s\tremaining: 3m 58s\n",
            "433:\tlearn: 0.2462701\ttotal: 3m 2s\tremaining: 3m 58s\n",
            "434:\tlearn: 0.2458377\ttotal: 3m 3s\tremaining: 3m 58s\n",
            "435:\tlearn: 0.2451081\ttotal: 3m 3s\tremaining: 3m 57s\n",
            "436:\tlearn: 0.2449433\ttotal: 3m 4s\tremaining: 3m 57s\n",
            "437:\tlearn: 0.2442095\ttotal: 3m 4s\tremaining: 3m 56s\n",
            "438:\tlearn: 0.2435724\ttotal: 3m 5s\tremaining: 3m 56s\n",
            "439:\tlearn: 0.2430856\ttotal: 3m 5s\tremaining: 3m 56s\n",
            "440:\tlearn: 0.2426085\ttotal: 3m 6s\tremaining: 3m 55s\n",
            "441:\tlearn: 0.2423336\ttotal: 3m 6s\tremaining: 3m 55s\n",
            "442:\tlearn: 0.2414867\ttotal: 3m 6s\tremaining: 3m 54s\n",
            "443:\tlearn: 0.2412139\ttotal: 3m 7s\tremaining: 3m 54s\n",
            "444:\tlearn: 0.2406885\ttotal: 3m 7s\tremaining: 3m 53s\n",
            "445:\tlearn: 0.2402554\ttotal: 3m 7s\tremaining: 3m 53s\n",
            "446:\tlearn: 0.2397826\ttotal: 3m 8s\tremaining: 3m 52s\n",
            "447:\tlearn: 0.2391617\ttotal: 3m 8s\tremaining: 3m 52s\n",
            "448:\tlearn: 0.2385280\ttotal: 3m 9s\tremaining: 3m 51s\n",
            "449:\tlearn: 0.2382071\ttotal: 3m 9s\tremaining: 3m 51s\n",
            "450:\tlearn: 0.2378524\ttotal: 3m 9s\tremaining: 3m 51s\n",
            "451:\tlearn: 0.2373410\ttotal: 3m 10s\tremaining: 3m 50s\n",
            "452:\tlearn: 0.2369156\ttotal: 3m 10s\tremaining: 3m 50s\n",
            "453:\tlearn: 0.2363712\ttotal: 3m 10s\tremaining: 3m 49s\n",
            "454:\tlearn: 0.2354024\ttotal: 3m 11s\tremaining: 3m 49s\n",
            "455:\tlearn: 0.2350124\ttotal: 3m 11s\tremaining: 3m 48s\n",
            "456:\tlearn: 0.2345419\ttotal: 3m 12s\tremaining: 3m 48s\n",
            "457:\tlearn: 0.2340430\ttotal: 3m 12s\tremaining: 3m 47s\n",
            "458:\tlearn: 0.2334571\ttotal: 3m 12s\tremaining: 3m 47s\n",
            "459:\tlearn: 0.2332562\ttotal: 3m 13s\tremaining: 3m 46s\n",
            "460:\tlearn: 0.2329628\ttotal: 3m 13s\tremaining: 3m 46s\n",
            "461:\tlearn: 0.2324737\ttotal: 3m 14s\tremaining: 3m 46s\n",
            "462:\tlearn: 0.2319680\ttotal: 3m 14s\tremaining: 3m 46s\n",
            "463:\tlearn: 0.2314158\ttotal: 3m 15s\tremaining: 3m 45s\n",
            "464:\tlearn: 0.2307779\ttotal: 3m 15s\tremaining: 3m 45s\n",
            "465:\tlearn: 0.2303533\ttotal: 3m 16s\tremaining: 3m 44s\n",
            "466:\tlearn: 0.2301467\ttotal: 3m 16s\tremaining: 3m 44s\n",
            "467:\tlearn: 0.2298617\ttotal: 3m 16s\tremaining: 3m 43s\n",
            "468:\tlearn: 0.2293875\ttotal: 3m 17s\tremaining: 3m 43s\n",
            "469:\tlearn: 0.2289291\ttotal: 3m 17s\tremaining: 3m 42s\n",
            "470:\tlearn: 0.2282228\ttotal: 3m 18s\tremaining: 3m 42s\n",
            "471:\tlearn: 0.2279795\ttotal: 3m 18s\tremaining: 3m 41s\n",
            "472:\tlearn: 0.2276424\ttotal: 3m 18s\tremaining: 3m 41s\n",
            "473:\tlearn: 0.2274505\ttotal: 3m 19s\tremaining: 3m 41s\n",
            "474:\tlearn: 0.2269752\ttotal: 3m 19s\tremaining: 3m 40s\n",
            "475:\tlearn: 0.2268878\ttotal: 3m 19s\tremaining: 3m 40s\n",
            "476:\tlearn: 0.2263318\ttotal: 3m 20s\tremaining: 3m 39s\n",
            "477:\tlearn: 0.2261887\ttotal: 3m 20s\tremaining: 3m 39s\n",
            "478:\tlearn: 0.2257604\ttotal: 3m 21s\tremaining: 3m 38s\n",
            "479:\tlearn: 0.2254422\ttotal: 3m 21s\tremaining: 3m 38s\n",
            "480:\tlearn: 0.2253403\ttotal: 3m 21s\tremaining: 3m 37s\n",
            "481:\tlearn: 0.2247972\ttotal: 3m 22s\tremaining: 3m 37s\n",
            "482:\tlearn: 0.2244787\ttotal: 3m 22s\tremaining: 3m 36s\n",
            "483:\tlearn: 0.2242909\ttotal: 3m 22s\tremaining: 3m 36s\n",
            "484:\tlearn: 0.2238223\ttotal: 3m 23s\tremaining: 3m 35s\n",
            "485:\tlearn: 0.2233500\ttotal: 3m 23s\tremaining: 3m 35s\n",
            "486:\tlearn: 0.2230804\ttotal: 3m 24s\tremaining: 3m 34s\n",
            "487:\tlearn: 0.2228531\ttotal: 3m 24s\tremaining: 3m 34s\n",
            "488:\tlearn: 0.2226495\ttotal: 3m 24s\tremaining: 3m 33s\n",
            "489:\tlearn: 0.2224279\ttotal: 3m 25s\tremaining: 3m 33s\n",
            "490:\tlearn: 0.2220487\ttotal: 3m 25s\tremaining: 3m 33s\n",
            "491:\tlearn: 0.2216071\ttotal: 3m 26s\tremaining: 3m 32s\n",
            "492:\tlearn: 0.2213851\ttotal: 3m 26s\tremaining: 3m 32s\n",
            "493:\tlearn: 0.2210950\ttotal: 3m 27s\tremaining: 3m 32s\n",
            "494:\tlearn: 0.2208305\ttotal: 3m 27s\tremaining: 3m 31s\n",
            "495:\tlearn: 0.2203810\ttotal: 3m 28s\tremaining: 3m 31s\n",
            "496:\tlearn: 0.2196908\ttotal: 3m 28s\tremaining: 3m 31s\n",
            "497:\tlearn: 0.2192426\ttotal: 3m 28s\tremaining: 3m 30s\n",
            "498:\tlearn: 0.2189504\ttotal: 3m 29s\tremaining: 3m 30s\n",
            "499:\tlearn: 0.2186322\ttotal: 3m 29s\tremaining: 3m 29s\n",
            "500:\tlearn: 0.2180417\ttotal: 3m 30s\tremaining: 3m 29s\n",
            "501:\tlearn: 0.2173672\ttotal: 3m 30s\tremaining: 3m 28s\n",
            "502:\tlearn: 0.2168517\ttotal: 3m 30s\tremaining: 3m 28s\n",
            "503:\tlearn: 0.2163712\ttotal: 3m 31s\tremaining: 3m 27s\n",
            "504:\tlearn: 0.2160021\ttotal: 3m 31s\tremaining: 3m 27s\n",
            "505:\tlearn: 0.2156578\ttotal: 3m 31s\tremaining: 3m 26s\n",
            "506:\tlearn: 0.2153781\ttotal: 3m 32s\tremaining: 3m 26s\n",
            "507:\tlearn: 0.2152115\ttotal: 3m 32s\tremaining: 3m 25s\n",
            "508:\tlearn: 0.2150154\ttotal: 3m 33s\tremaining: 3m 25s\n",
            "509:\tlearn: 0.2145466\ttotal: 3m 33s\tremaining: 3m 25s\n",
            "510:\tlearn: 0.2142128\ttotal: 3m 33s\tremaining: 3m 24s\n",
            "511:\tlearn: 0.2139206\ttotal: 3m 34s\tremaining: 3m 24s\n",
            "512:\tlearn: 0.2135733\ttotal: 3m 34s\tremaining: 3m 23s\n",
            "513:\tlearn: 0.2132089\ttotal: 3m 34s\tremaining: 3m 23s\n",
            "514:\tlearn: 0.2129348\ttotal: 3m 35s\tremaining: 3m 22s\n",
            "515:\tlearn: 0.2126818\ttotal: 3m 35s\tremaining: 3m 22s\n",
            "516:\tlearn: 0.2119262\ttotal: 3m 36s\tremaining: 3m 21s\n",
            "517:\tlearn: 0.2117500\ttotal: 3m 36s\tremaining: 3m 21s\n",
            "518:\tlearn: 0.2113372\ttotal: 3m 36s\tremaining: 3m 20s\n",
            "519:\tlearn: 0.2110783\ttotal: 3m 37s\tremaining: 3m 20s\n",
            "520:\tlearn: 0.2106596\ttotal: 3m 37s\tremaining: 3m 20s\n",
            "521:\tlearn: 0.2102556\ttotal: 3m 38s\tremaining: 3m 19s\n",
            "522:\tlearn: 0.2099465\ttotal: 3m 38s\tremaining: 3m 19s\n",
            "523:\tlearn: 0.2097142\ttotal: 3m 39s\tremaining: 3m 19s\n",
            "524:\tlearn: 0.2095529\ttotal: 3m 39s\tremaining: 3m 18s\n",
            "525:\tlearn: 0.2092721\ttotal: 3m 40s\tremaining: 3m 18s\n",
            "526:\tlearn: 0.2090588\ttotal: 3m 40s\tremaining: 3m 17s\n",
            "527:\tlearn: 0.2087800\ttotal: 3m 40s\tremaining: 3m 17s\n",
            "528:\tlearn: 0.2084089\ttotal: 3m 41s\tremaining: 3m 16s\n",
            "529:\tlearn: 0.2079285\ttotal: 3m 41s\tremaining: 3m 16s\n",
            "530:\tlearn: 0.2072744\ttotal: 3m 41s\tremaining: 3m 16s\n",
            "531:\tlearn: 0.2070713\ttotal: 3m 42s\tremaining: 3m 15s\n",
            "532:\tlearn: 0.2067679\ttotal: 3m 42s\tremaining: 3m 15s\n",
            "533:\tlearn: 0.2066796\ttotal: 3m 43s\tremaining: 3m 14s\n",
            "534:\tlearn: 0.2065593\ttotal: 3m 43s\tremaining: 3m 14s\n",
            "535:\tlearn: 0.2062642\ttotal: 3m 43s\tremaining: 3m 13s\n",
            "536:\tlearn: 0.2059505\ttotal: 3m 44s\tremaining: 3m 13s\n",
            "537:\tlearn: 0.2056748\ttotal: 3m 44s\tremaining: 3m 12s\n",
            "538:\tlearn: 0.2051638\ttotal: 3m 44s\tremaining: 3m 12s\n",
            "539:\tlearn: 0.2047705\ttotal: 3m 45s\tremaining: 3m 11s\n",
            "540:\tlearn: 0.2045127\ttotal: 3m 45s\tremaining: 3m 11s\n",
            "541:\tlearn: 0.2043758\ttotal: 3m 46s\tremaining: 3m 11s\n",
            "542:\tlearn: 0.2041375\ttotal: 3m 46s\tremaining: 3m 10s\n",
            "543:\tlearn: 0.2038866\ttotal: 3m 46s\tremaining: 3m 10s\n",
            "544:\tlearn: 0.2034404\ttotal: 3m 47s\tremaining: 3m 9s\n",
            "545:\tlearn: 0.2029395\ttotal: 3m 47s\tremaining: 3m 9s\n",
            "546:\tlearn: 0.2025460\ttotal: 3m 47s\tremaining: 3m 8s\n",
            "547:\tlearn: 0.2020125\ttotal: 3m 48s\tremaining: 3m 8s\n",
            "548:\tlearn: 0.2015270\ttotal: 3m 48s\tremaining: 3m 7s\n",
            "549:\tlearn: 0.2010369\ttotal: 3m 49s\tremaining: 3m 7s\n",
            "550:\tlearn: 0.2008611\ttotal: 3m 49s\tremaining: 3m 7s\n",
            "551:\tlearn: 0.2005298\ttotal: 3m 50s\tremaining: 3m 6s\n",
            "552:\tlearn: 0.2001897\ttotal: 3m 50s\tremaining: 3m 6s\n",
            "553:\tlearn: 0.1998217\ttotal: 3m 51s\tremaining: 3m 6s\n",
            "554:\tlearn: 0.1994870\ttotal: 3m 51s\tremaining: 3m 5s\n",
            "555:\tlearn: 0.1992812\ttotal: 3m 52s\tremaining: 3m 5s\n",
            "556:\tlearn: 0.1989305\ttotal: 3m 52s\tremaining: 3m 4s\n",
            "557:\tlearn: 0.1986549\ttotal: 3m 52s\tremaining: 3m 4s\n",
            "558:\tlearn: 0.1981271\ttotal: 3m 53s\tremaining: 3m 4s\n",
            "559:\tlearn: 0.1978237\ttotal: 3m 53s\tremaining: 3m 3s\n",
            "560:\tlearn: 0.1975163\ttotal: 3m 54s\tremaining: 3m 3s\n",
            "561:\tlearn: 0.1970324\ttotal: 3m 54s\tremaining: 3m 2s\n",
            "562:\tlearn: 0.1968944\ttotal: 3m 54s\tremaining: 3m 2s\n",
            "563:\tlearn: 0.1964223\ttotal: 3m 55s\tremaining: 3m 1s\n",
            "564:\tlearn: 0.1962509\ttotal: 3m 55s\tremaining: 3m 1s\n",
            "565:\tlearn: 0.1961546\ttotal: 3m 55s\tremaining: 3m\n",
            "566:\tlearn: 0.1959535\ttotal: 3m 56s\tremaining: 3m\n",
            "567:\tlearn: 0.1954129\ttotal: 3m 56s\tremaining: 2m 59s\n",
            "568:\tlearn: 0.1949870\ttotal: 3m 56s\tremaining: 2m 59s\n",
            "569:\tlearn: 0.1947685\ttotal: 3m 57s\tremaining: 2m 59s\n",
            "570:\tlearn: 0.1944988\ttotal: 3m 57s\tremaining: 2m 58s\n",
            "571:\tlearn: 0.1941450\ttotal: 3m 58s\tremaining: 2m 58s\n",
            "572:\tlearn: 0.1937038\ttotal: 3m 58s\tremaining: 2m 57s\n",
            "573:\tlearn: 0.1933267\ttotal: 3m 58s\tremaining: 2m 57s\n",
            "574:\tlearn: 0.1929224\ttotal: 3m 59s\tremaining: 2m 56s\n",
            "575:\tlearn: 0.1927890\ttotal: 3m 59s\tremaining: 2m 56s\n",
            "576:\tlearn: 0.1924102\ttotal: 3m 59s\tremaining: 2m 55s\n",
            "577:\tlearn: 0.1921008\ttotal: 4m\tremaining: 2m 55s\n",
            "578:\tlearn: 0.1915738\ttotal: 4m\tremaining: 2m 54s\n",
            "579:\tlearn: 0.1909757\ttotal: 4m 1s\tremaining: 2m 54s\n",
            "580:\tlearn: 0.1905454\ttotal: 4m 1s\tremaining: 2m 54s\n",
            "581:\tlearn: 0.1902788\ttotal: 4m 2s\tremaining: 2m 54s\n",
            "582:\tlearn: 0.1900051\ttotal: 4m 3s\tremaining: 2m 53s\n",
            "583:\tlearn: 0.1896650\ttotal: 4m 3s\tremaining: 2m 53s\n",
            "584:\tlearn: 0.1889684\ttotal: 4m 3s\tremaining: 2m 52s\n",
            "585:\tlearn: 0.1887017\ttotal: 4m 4s\tremaining: 2m 52s\n",
            "586:\tlearn: 0.1883673\ttotal: 4m 4s\tremaining: 2m 52s\n",
            "587:\tlearn: 0.1880464\ttotal: 4m 4s\tremaining: 2m 51s\n",
            "588:\tlearn: 0.1877639\ttotal: 4m 5s\tremaining: 2m 51s\n",
            "589:\tlearn: 0.1871531\ttotal: 4m 5s\tremaining: 2m 50s\n",
            "590:\tlearn: 0.1867594\ttotal: 4m 5s\tremaining: 2m 50s\n",
            "591:\tlearn: 0.1865071\ttotal: 4m 6s\tremaining: 2m 49s\n",
            "592:\tlearn: 0.1861485\ttotal: 4m 6s\tremaining: 2m 49s\n",
            "593:\tlearn: 0.1859360\ttotal: 4m 7s\tremaining: 2m 48s\n",
            "594:\tlearn: 0.1858749\ttotal: 4m 7s\tremaining: 2m 48s\n",
            "595:\tlearn: 0.1855654\ttotal: 4m 7s\tremaining: 2m 48s\n",
            "596:\tlearn: 0.1851263\ttotal: 4m 8s\tremaining: 2m 47s\n",
            "597:\tlearn: 0.1850182\ttotal: 4m 9s\tremaining: 2m 47s\n",
            "598:\tlearn: 0.1844755\ttotal: 4m 9s\tremaining: 2m 47s\n",
            "599:\tlearn: 0.1840952\ttotal: 4m 10s\tremaining: 2m 46s\n",
            "600:\tlearn: 0.1838045\ttotal: 4m 10s\tremaining: 2m 46s\n",
            "601:\tlearn: 0.1836163\ttotal: 4m 10s\tremaining: 2m 45s\n",
            "602:\tlearn: 0.1833616\ttotal: 4m 11s\tremaining: 2m 45s\n",
            "603:\tlearn: 0.1832326\ttotal: 4m 11s\tremaining: 2m 45s\n",
            "604:\tlearn: 0.1831227\ttotal: 4m 12s\tremaining: 2m 44s\n",
            "605:\tlearn: 0.1829019\ttotal: 4m 12s\tremaining: 2m 44s\n",
            "606:\tlearn: 0.1824012\ttotal: 4m 12s\tremaining: 2m 43s\n",
            "607:\tlearn: 0.1819689\ttotal: 4m 13s\tremaining: 2m 43s\n",
            "608:\tlearn: 0.1815342\ttotal: 4m 13s\tremaining: 2m 43s\n",
            "609:\tlearn: 0.1813340\ttotal: 4m 14s\tremaining: 2m 42s\n",
            "610:\tlearn: 0.1810785\ttotal: 4m 15s\tremaining: 2m 42s\n",
            "611:\tlearn: 0.1806755\ttotal: 4m 15s\tremaining: 2m 41s\n",
            "612:\tlearn: 0.1805776\ttotal: 4m 15s\tremaining: 2m 41s\n",
            "613:\tlearn: 0.1803352\ttotal: 4m 16s\tremaining: 2m 41s\n",
            "614:\tlearn: 0.1801180\ttotal: 4m 16s\tremaining: 2m 40s\n",
            "615:\tlearn: 0.1797312\ttotal: 4m 16s\tremaining: 2m 40s\n",
            "616:\tlearn: 0.1794066\ttotal: 4m 17s\tremaining: 2m 39s\n",
            "617:\tlearn: 0.1789626\ttotal: 4m 17s\tremaining: 2m 39s\n",
            "618:\tlearn: 0.1787119\ttotal: 4m 18s\tremaining: 2m 38s\n",
            "619:\tlearn: 0.1785923\ttotal: 4m 18s\tremaining: 2m 38s\n",
            "620:\tlearn: 0.1783779\ttotal: 4m 18s\tremaining: 2m 37s\n",
            "621:\tlearn: 0.1781390\ttotal: 4m 19s\tremaining: 2m 37s\n",
            "622:\tlearn: 0.1780501\ttotal: 4m 19s\tremaining: 2m 37s\n",
            "623:\tlearn: 0.1779712\ttotal: 4m 19s\tremaining: 2m 36s\n",
            "624:\tlearn: 0.1774863\ttotal: 4m 20s\tremaining: 2m 36s\n",
            "625:\tlearn: 0.1768786\ttotal: 4m 20s\tremaining: 2m 35s\n",
            "626:\tlearn: 0.1767610\ttotal: 4m 21s\tremaining: 2m 35s\n",
            "627:\tlearn: 0.1763900\ttotal: 4m 21s\tremaining: 2m 34s\n",
            "628:\tlearn: 0.1759845\ttotal: 4m 21s\tremaining: 2m 34s\n",
            "629:\tlearn: 0.1758068\ttotal: 4m 22s\tremaining: 2m 33s\n",
            "630:\tlearn: 0.1754877\ttotal: 4m 22s\tremaining: 2m 33s\n",
            "631:\tlearn: 0.1752066\ttotal: 4m 22s\tremaining: 2m 33s\n",
            "632:\tlearn: 0.1748566\ttotal: 4m 23s\tremaining: 2m 32s\n",
            "633:\tlearn: 0.1746761\ttotal: 4m 23s\tremaining: 2m 32s\n",
            "634:\tlearn: 0.1743526\ttotal: 4m 24s\tremaining: 2m 31s\n",
            "635:\tlearn: 0.1740135\ttotal: 4m 24s\tremaining: 2m 31s\n",
            "636:\tlearn: 0.1737873\ttotal: 4m 24s\tremaining: 2m 30s\n",
            "637:\tlearn: 0.1736944\ttotal: 4m 25s\tremaining: 2m 30s\n",
            "638:\tlearn: 0.1735621\ttotal: 4m 25s\tremaining: 2m 30s\n",
            "639:\tlearn: 0.1732449\ttotal: 4m 26s\tremaining: 2m 29s\n",
            "640:\tlearn: 0.1730684\ttotal: 4m 27s\tremaining: 2m 29s\n",
            "641:\tlearn: 0.1726540\ttotal: 4m 27s\tremaining: 2m 29s\n",
            "642:\tlearn: 0.1724256\ttotal: 4m 27s\tremaining: 2m 28s\n",
            "643:\tlearn: 0.1721420\ttotal: 4m 28s\tremaining: 2m 28s\n",
            "644:\tlearn: 0.1716300\ttotal: 4m 28s\tremaining: 2m 27s\n",
            "645:\tlearn: 0.1713238\ttotal: 4m 28s\tremaining: 2m 27s\n",
            "646:\tlearn: 0.1710047\ttotal: 4m 29s\tremaining: 2m 26s\n",
            "647:\tlearn: 0.1705695\ttotal: 4m 29s\tremaining: 2m 26s\n",
            "648:\tlearn: 0.1703346\ttotal: 4m 30s\tremaining: 2m 26s\n",
            "649:\tlearn: 0.1700803\ttotal: 4m 30s\tremaining: 2m 25s\n",
            "650:\tlearn: 0.1696626\ttotal: 4m 30s\tremaining: 2m 25s\n",
            "651:\tlearn: 0.1691689\ttotal: 4m 31s\tremaining: 2m 24s\n",
            "652:\tlearn: 0.1690769\ttotal: 4m 31s\tremaining: 2m 24s\n",
            "653:\tlearn: 0.1688849\ttotal: 4m 31s\tremaining: 2m 23s\n",
            "654:\tlearn: 0.1687291\ttotal: 4m 32s\tremaining: 2m 23s\n",
            "655:\tlearn: 0.1682497\ttotal: 4m 32s\tremaining: 2m 22s\n",
            "656:\tlearn: 0.1679793\ttotal: 4m 33s\tremaining: 2m 22s\n",
            "657:\tlearn: 0.1677245\ttotal: 4m 33s\tremaining: 2m 22s\n",
            "658:\tlearn: 0.1674959\ttotal: 4m 33s\tremaining: 2m 21s\n",
            "659:\tlearn: 0.1671314\ttotal: 4m 34s\tremaining: 2m 21s\n",
            "660:\tlearn: 0.1668180\ttotal: 4m 34s\tremaining: 2m 20s\n",
            "661:\tlearn: 0.1665749\ttotal: 4m 34s\tremaining: 2m 20s\n",
            "662:\tlearn: 0.1660809\ttotal: 4m 35s\tremaining: 2m 19s\n",
            "663:\tlearn: 0.1660196\ttotal: 4m 35s\tremaining: 2m 19s\n",
            "664:\tlearn: 0.1658332\ttotal: 4m 36s\tremaining: 2m 19s\n",
            "665:\tlearn: 0.1656602\ttotal: 4m 36s\tremaining: 2m 18s\n",
            "666:\tlearn: 0.1654589\ttotal: 4m 36s\tremaining: 2m 18s\n",
            "667:\tlearn: 0.1652441\ttotal: 4m 37s\tremaining: 2m 17s\n",
            "668:\tlearn: 0.1650191\ttotal: 4m 37s\tremaining: 2m 17s\n",
            "669:\tlearn: 0.1647168\ttotal: 4m 38s\tremaining: 2m 17s\n",
            "670:\tlearn: 0.1644302\ttotal: 4m 39s\tremaining: 2m 16s\n",
            "671:\tlearn: 0.1642022\ttotal: 4m 39s\tremaining: 2m 16s\n",
            "672:\tlearn: 0.1637838\ttotal: 4m 39s\tremaining: 2m 15s\n",
            "673:\tlearn: 0.1635104\ttotal: 4m 40s\tremaining: 2m 15s\n",
            "674:\tlearn: 0.1634132\ttotal: 4m 40s\tremaining: 2m 15s\n",
            "675:\tlearn: 0.1632004\ttotal: 4m 40s\tremaining: 2m 14s\n",
            "676:\tlearn: 0.1631457\ttotal: 4m 41s\tremaining: 2m 14s\n",
            "677:\tlearn: 0.1628822\ttotal: 4m 41s\tremaining: 2m 13s\n",
            "678:\tlearn: 0.1627428\ttotal: 4m 42s\tremaining: 2m 13s\n",
            "679:\tlearn: 0.1623556\ttotal: 4m 42s\tremaining: 2m 12s\n",
            "680:\tlearn: 0.1621743\ttotal: 4m 42s\tremaining: 2m 12s\n",
            "681:\tlearn: 0.1620745\ttotal: 4m 43s\tremaining: 2m 12s\n",
            "682:\tlearn: 0.1616071\ttotal: 4m 43s\tremaining: 2m 11s\n",
            "683:\tlearn: 0.1612292\ttotal: 4m 43s\tremaining: 2m 11s\n",
            "684:\tlearn: 0.1611316\ttotal: 4m 44s\tremaining: 2m 10s\n",
            "685:\tlearn: 0.1610504\ttotal: 4m 44s\tremaining: 2m 10s\n",
            "686:\tlearn: 0.1606857\ttotal: 4m 45s\tremaining: 2m 9s\n",
            "687:\tlearn: 0.1601623\ttotal: 4m 45s\tremaining: 2m 9s\n",
            "688:\tlearn: 0.1597434\ttotal: 4m 45s\tremaining: 2m 9s\n",
            "689:\tlearn: 0.1595197\ttotal: 4m 46s\tremaining: 2m 8s\n",
            "690:\tlearn: 0.1593310\ttotal: 4m 46s\tremaining: 2m 8s\n",
            "691:\tlearn: 0.1592364\ttotal: 4m 46s\tremaining: 2m 7s\n",
            "692:\tlearn: 0.1591192\ttotal: 4m 47s\tremaining: 2m 7s\n",
            "693:\tlearn: 0.1588889\ttotal: 4m 47s\tremaining: 2m 6s\n",
            "694:\tlearn: 0.1585231\ttotal: 4m 47s\tremaining: 2m 6s\n",
            "695:\tlearn: 0.1582924\ttotal: 4m 48s\tremaining: 2m 5s\n",
            "696:\tlearn: 0.1581193\ttotal: 4m 48s\tremaining: 2m 5s\n",
            "697:\tlearn: 0.1580143\ttotal: 4m 49s\tremaining: 2m 5s\n",
            "698:\tlearn: 0.1578845\ttotal: 4m 50s\tremaining: 2m 4s\n",
            "699:\tlearn: 0.1576083\ttotal: 4m 50s\tremaining: 2m 4s\n",
            "700:\tlearn: 0.1575305\ttotal: 4m 51s\tremaining: 2m 4s\n",
            "701:\tlearn: 0.1574328\ttotal: 4m 51s\tremaining: 2m 3s\n",
            "702:\tlearn: 0.1572076\ttotal: 4m 52s\tremaining: 2m 3s\n",
            "703:\tlearn: 0.1570289\ttotal: 4m 52s\tremaining: 2m 3s\n",
            "704:\tlearn: 0.1567826\ttotal: 4m 52s\tremaining: 2m 2s\n",
            "705:\tlearn: 0.1565384\ttotal: 4m 53s\tremaining: 2m 2s\n",
            "706:\tlearn: 0.1562818\ttotal: 4m 53s\tremaining: 2m 1s\n",
            "707:\tlearn: 0.1559882\ttotal: 4m 54s\tremaining: 2m 1s\n",
            "708:\tlearn: 0.1557678\ttotal: 4m 54s\tremaining: 2m\n",
            "709:\tlearn: 0.1556351\ttotal: 4m 54s\tremaining: 2m\n",
            "710:\tlearn: 0.1552701\ttotal: 4m 55s\tremaining: 2m\n",
            "711:\tlearn: 0.1550212\ttotal: 4m 55s\tremaining: 1m 59s\n",
            "712:\tlearn: 0.1547134\ttotal: 4m 56s\tremaining: 1m 59s\n",
            "713:\tlearn: 0.1544552\ttotal: 4m 56s\tremaining: 1m 58s\n",
            "714:\tlearn: 0.1543046\ttotal: 4m 56s\tremaining: 1m 58s\n",
            "715:\tlearn: 0.1539950\ttotal: 4m 57s\tremaining: 1m 57s\n",
            "716:\tlearn: 0.1538803\ttotal: 4m 57s\tremaining: 1m 57s\n",
            "717:\tlearn: 0.1536123\ttotal: 4m 58s\tremaining: 1m 57s\n",
            "718:\tlearn: 0.1533670\ttotal: 4m 58s\tremaining: 1m 56s\n",
            "719:\tlearn: 0.1532984\ttotal: 4m 58s\tremaining: 1m 56s\n",
            "720:\tlearn: 0.1530303\ttotal: 4m 59s\tremaining: 1m 55s\n",
            "721:\tlearn: 0.1525333\ttotal: 4m 59s\tremaining: 1m 55s\n",
            "722:\tlearn: 0.1524184\ttotal: 4m 59s\tremaining: 1m 54s\n",
            "723:\tlearn: 0.1522920\ttotal: 5m\tremaining: 1m 54s\n",
            "724:\tlearn: 0.1520301\ttotal: 5m\tremaining: 1m 54s\n",
            "725:\tlearn: 0.1516859\ttotal: 5m 1s\tremaining: 1m 53s\n",
            "726:\tlearn: 0.1514573\ttotal: 5m 1s\tremaining: 1m 53s\n",
            "727:\tlearn: 0.1509958\ttotal: 5m 2s\tremaining: 1m 53s\n",
            "728:\tlearn: 0.1508243\ttotal: 5m 2s\tremaining: 1m 52s\n",
            "729:\tlearn: 0.1507086\ttotal: 5m 3s\tremaining: 1m 52s\n",
            "730:\tlearn: 0.1505938\ttotal: 5m 3s\tremaining: 1m 51s\n",
            "731:\tlearn: 0.1504282\ttotal: 5m 4s\tremaining: 1m 51s\n",
            "732:\tlearn: 0.1501359\ttotal: 5m 4s\tremaining: 1m 50s\n",
            "733:\tlearn: 0.1499021\ttotal: 5m 4s\tremaining: 1m 50s\n",
            "734:\tlearn: 0.1497767\ttotal: 5m 5s\tremaining: 1m 50s\n",
            "735:\tlearn: 0.1496647\ttotal: 5m 5s\tremaining: 1m 49s\n",
            "736:\tlearn: 0.1494987\ttotal: 5m 5s\tremaining: 1m 49s\n",
            "737:\tlearn: 0.1493417\ttotal: 5m 6s\tremaining: 1m 48s\n",
            "738:\tlearn: 0.1492226\ttotal: 5m 6s\tremaining: 1m 48s\n",
            "739:\tlearn: 0.1489412\ttotal: 5m 7s\tremaining: 1m 47s\n",
            "740:\tlearn: 0.1487114\ttotal: 5m 7s\tremaining: 1m 47s\n",
            "741:\tlearn: 0.1483838\ttotal: 5m 7s\tremaining: 1m 47s\n",
            "742:\tlearn: 0.1481323\ttotal: 5m 8s\tremaining: 1m 46s\n",
            "743:\tlearn: 0.1479326\ttotal: 5m 8s\tremaining: 1m 46s\n",
            "744:\tlearn: 0.1478170\ttotal: 5m 8s\tremaining: 1m 45s\n",
            "745:\tlearn: 0.1475527\ttotal: 5m 9s\tremaining: 1m 45s\n",
            "746:\tlearn: 0.1473111\ttotal: 5m 9s\tremaining: 1m 44s\n",
            "747:\tlearn: 0.1471854\ttotal: 5m 10s\tremaining: 1m 44s\n",
            "748:\tlearn: 0.1470394\ttotal: 5m 10s\tremaining: 1m 44s\n",
            "749:\tlearn: 0.1466241\ttotal: 5m 10s\tremaining: 1m 43s\n",
            "750:\tlearn: 0.1464829\ttotal: 5m 11s\tremaining: 1m 43s\n",
            "751:\tlearn: 0.1462599\ttotal: 5m 11s\tremaining: 1m 42s\n",
            "752:\tlearn: 0.1461339\ttotal: 5m 11s\tremaining: 1m 42s\n",
            "753:\tlearn: 0.1458740\ttotal: 5m 12s\tremaining: 1m 41s\n",
            "754:\tlearn: 0.1457265\ttotal: 5m 12s\tremaining: 1m 41s\n",
            "755:\tlearn: 0.1453993\ttotal: 5m 13s\tremaining: 1m 41s\n",
            "756:\tlearn: 0.1450708\ttotal: 5m 14s\tremaining: 1m 40s\n",
            "757:\tlearn: 0.1449811\ttotal: 5m 14s\tremaining: 1m 40s\n",
            "758:\tlearn: 0.1448893\ttotal: 5m 14s\tremaining: 1m 40s\n",
            "759:\tlearn: 0.1446645\ttotal: 5m 15s\tremaining: 1m 39s\n",
            "760:\tlearn: 0.1444036\ttotal: 5m 15s\tremaining: 1m 39s\n",
            "761:\tlearn: 0.1442830\ttotal: 5m 16s\tremaining: 1m 38s\n",
            "762:\tlearn: 0.1440895\ttotal: 5m 16s\tremaining: 1m 38s\n",
            "763:\tlearn: 0.1438264\ttotal: 5m 16s\tremaining: 1m 37s\n",
            "764:\tlearn: 0.1437083\ttotal: 5m 17s\tremaining: 1m 37s\n",
            "765:\tlearn: 0.1435255\ttotal: 5m 17s\tremaining: 1m 37s\n",
            "766:\tlearn: 0.1433734\ttotal: 5m 17s\tremaining: 1m 36s\n",
            "767:\tlearn: 0.1431897\ttotal: 5m 18s\tremaining: 1m 36s\n",
            "768:\tlearn: 0.1430787\ttotal: 5m 18s\tremaining: 1m 35s\n",
            "769:\tlearn: 0.1427335\ttotal: 5m 19s\tremaining: 1m 35s\n",
            "770:\tlearn: 0.1426921\ttotal: 5m 19s\tremaining: 1m 34s\n",
            "771:\tlearn: 0.1424984\ttotal: 5m 19s\tremaining: 1m 34s\n",
            "772:\tlearn: 0.1423742\ttotal: 5m 20s\tremaining: 1m 34s\n",
            "773:\tlearn: 0.1420649\ttotal: 5m 20s\tremaining: 1m 33s\n",
            "774:\tlearn: 0.1418879\ttotal: 5m 20s\tremaining: 1m 33s\n",
            "775:\tlearn: 0.1418081\ttotal: 5m 21s\tremaining: 1m 32s\n",
            "776:\tlearn: 0.1415901\ttotal: 5m 21s\tremaining: 1m 32s\n",
            "777:\tlearn: 0.1412007\ttotal: 5m 22s\tremaining: 1m 31s\n",
            "778:\tlearn: 0.1410145\ttotal: 5m 22s\tremaining: 1m 31s\n",
            "779:\tlearn: 0.1408508\ttotal: 5m 22s\tremaining: 1m 31s\n",
            "780:\tlearn: 0.1406460\ttotal: 5m 23s\tremaining: 1m 30s\n",
            "781:\tlearn: 0.1405099\ttotal: 5m 23s\tremaining: 1m 30s\n",
            "782:\tlearn: 0.1404176\ttotal: 5m 23s\tremaining: 1m 29s\n",
            "783:\tlearn: 0.1401941\ttotal: 5m 24s\tremaining: 1m 29s\n",
            "784:\tlearn: 0.1400260\ttotal: 5m 24s\tremaining: 1m 28s\n",
            "785:\tlearn: 0.1398990\ttotal: 5m 25s\tremaining: 1m 28s\n",
            "786:\tlearn: 0.1397893\ttotal: 5m 26s\tremaining: 1m 28s\n",
            "787:\tlearn: 0.1396394\ttotal: 5m 26s\tremaining: 1m 27s\n",
            "788:\tlearn: 0.1394917\ttotal: 5m 27s\tremaining: 1m 27s\n",
            "789:\tlearn: 0.1393257\ttotal: 5m 27s\tremaining: 1m 27s\n",
            "790:\tlearn: 0.1391144\ttotal: 5m 27s\tremaining: 1m 26s\n",
            "791:\tlearn: 0.1388981\ttotal: 5m 28s\tremaining: 1m 26s\n",
            "792:\tlearn: 0.1388052\ttotal: 5m 28s\tremaining: 1m 25s\n",
            "793:\tlearn: 0.1385240\ttotal: 5m 28s\tremaining: 1m 25s\n",
            "794:\tlearn: 0.1383690\ttotal: 5m 29s\tremaining: 1m 24s\n",
            "795:\tlearn: 0.1382306\ttotal: 5m 29s\tremaining: 1m 24s\n",
            "796:\tlearn: 0.1381181\ttotal: 5m 30s\tremaining: 1m 24s\n",
            "797:\tlearn: 0.1378391\ttotal: 5m 30s\tremaining: 1m 23s\n",
            "798:\tlearn: 0.1376374\ttotal: 5m 30s\tremaining: 1m 23s\n",
            "799:\tlearn: 0.1372534\ttotal: 5m 31s\tremaining: 1m 22s\n",
            "800:\tlearn: 0.1370652\ttotal: 5m 31s\tremaining: 1m 22s\n",
            "801:\tlearn: 0.1369560\ttotal: 5m 31s\tremaining: 1m 21s\n",
            "802:\tlearn: 0.1367339\ttotal: 5m 32s\tremaining: 1m 21s\n",
            "803:\tlearn: 0.1363724\ttotal: 5m 32s\tremaining: 1m 21s\n",
            "804:\tlearn: 0.1361139\ttotal: 5m 33s\tremaining: 1m 20s\n",
            "805:\tlearn: 0.1360127\ttotal: 5m 33s\tremaining: 1m 20s\n",
            "806:\tlearn: 0.1357222\ttotal: 5m 33s\tremaining: 1m 19s\n",
            "807:\tlearn: 0.1354985\ttotal: 5m 34s\tremaining: 1m 19s\n",
            "808:\tlearn: 0.1354120\ttotal: 5m 34s\tremaining: 1m 18s\n",
            "809:\tlearn: 0.1351973\ttotal: 5m 34s\tremaining: 1m 18s\n",
            "810:\tlearn: 0.1349653\ttotal: 5m 35s\tremaining: 1m 18s\n",
            "811:\tlearn: 0.1347127\ttotal: 5m 35s\tremaining: 1m 17s\n",
            "812:\tlearn: 0.1345256\ttotal: 5m 36s\tremaining: 1m 17s\n",
            "813:\tlearn: 0.1341451\ttotal: 5m 36s\tremaining: 1m 16s\n",
            "814:\tlearn: 0.1337095\ttotal: 5m 37s\tremaining: 1m 16s\n",
            "815:\tlearn: 0.1335823\ttotal: 5m 37s\tremaining: 1m 16s\n",
            "816:\tlearn: 0.1332939\ttotal: 5m 38s\tremaining: 1m 15s\n",
            "817:\tlearn: 0.1331080\ttotal: 5m 38s\tremaining: 1m 15s\n",
            "818:\tlearn: 0.1328601\ttotal: 5m 39s\tremaining: 1m 14s\n",
            "819:\tlearn: 0.1324918\ttotal: 5m 39s\tremaining: 1m 14s\n",
            "820:\tlearn: 0.1324125\ttotal: 5m 39s\tremaining: 1m 14s\n",
            "821:\tlearn: 0.1323412\ttotal: 5m 40s\tremaining: 1m 13s\n",
            "822:\tlearn: 0.1322367\ttotal: 5m 40s\tremaining: 1m 13s\n",
            "823:\tlearn: 0.1321571\ttotal: 5m 40s\tremaining: 1m 12s\n",
            "824:\tlearn: 0.1320609\ttotal: 5m 41s\tremaining: 1m 12s\n",
            "825:\tlearn: 0.1319374\ttotal: 5m 41s\tremaining: 1m 11s\n",
            "826:\tlearn: 0.1316756\ttotal: 5m 42s\tremaining: 1m 11s\n",
            "827:\tlearn: 0.1315148\ttotal: 5m 42s\tremaining: 1m 11s\n",
            "828:\tlearn: 0.1311776\ttotal: 5m 42s\tremaining: 1m 10s\n",
            "829:\tlearn: 0.1310598\ttotal: 5m 43s\tremaining: 1m 10s\n",
            "830:\tlearn: 0.1307440\ttotal: 5m 43s\tremaining: 1m 9s\n",
            "831:\tlearn: 0.1305186\ttotal: 5m 43s\tremaining: 1m 9s\n",
            "832:\tlearn: 0.1304088\ttotal: 5m 44s\tremaining: 1m 9s\n",
            "833:\tlearn: 0.1303526\ttotal: 5m 44s\tremaining: 1m 8s\n",
            "834:\tlearn: 0.1301618\ttotal: 5m 45s\tremaining: 1m 8s\n",
            "835:\tlearn: 0.1301266\ttotal: 5m 45s\tremaining: 1m 7s\n",
            "836:\tlearn: 0.1297144\ttotal: 5m 45s\tremaining: 1m 7s\n",
            "837:\tlearn: 0.1295422\ttotal: 5m 46s\tremaining: 1m 6s\n",
            "838:\tlearn: 0.1292956\ttotal: 5m 46s\tremaining: 1m 6s\n",
            "839:\tlearn: 0.1291122\ttotal: 5m 46s\tremaining: 1m 6s\n",
            "840:\tlearn: 0.1288588\ttotal: 5m 47s\tremaining: 1m 5s\n",
            "841:\tlearn: 0.1284977\ttotal: 5m 47s\tremaining: 1m 5s\n",
            "842:\tlearn: 0.1283949\ttotal: 5m 48s\tremaining: 1m 4s\n",
            "843:\tlearn: 0.1282336\ttotal: 5m 48s\tremaining: 1m 4s\n",
            "844:\tlearn: 0.1278695\ttotal: 5m 49s\tremaining: 1m 4s\n",
            "845:\tlearn: 0.1276785\ttotal: 5m 49s\tremaining: 1m 3s\n",
            "846:\tlearn: 0.1276061\ttotal: 5m 50s\tremaining: 1m 3s\n",
            "847:\tlearn: 0.1273920\ttotal: 5m 50s\tremaining: 1m 2s\n",
            "848:\tlearn: 0.1271870\ttotal: 5m 51s\tremaining: 1m 2s\n",
            "849:\tlearn: 0.1269890\ttotal: 5m 51s\tremaining: 1m 2s\n",
            "850:\tlearn: 0.1267783\ttotal: 5m 51s\tremaining: 1m 1s\n",
            "851:\tlearn: 0.1265776\ttotal: 5m 52s\tremaining: 1m 1s\n",
            "852:\tlearn: 0.1263881\ttotal: 5m 52s\tremaining: 1m\n",
            "853:\tlearn: 0.1262145\ttotal: 5m 52s\tremaining: 1m\n",
            "854:\tlearn: 0.1260322\ttotal: 5m 53s\tremaining: 59.9s\n",
            "855:\tlearn: 0.1257014\ttotal: 5m 53s\tremaining: 59.5s\n",
            "856:\tlearn: 0.1255791\ttotal: 5m 54s\tremaining: 59.1s\n",
            "857:\tlearn: 0.1254101\ttotal: 5m 54s\tremaining: 58.7s\n",
            "858:\tlearn: 0.1251818\ttotal: 5m 54s\tremaining: 58.2s\n",
            "859:\tlearn: 0.1251048\ttotal: 5m 55s\tremaining: 57.8s\n",
            "860:\tlearn: 0.1249848\ttotal: 5m 55s\tremaining: 57.4s\n",
            "861:\tlearn: 0.1247482\ttotal: 5m 55s\tremaining: 57s\n",
            "862:\tlearn: 0.1246500\ttotal: 5m 56s\tremaining: 56.6s\n",
            "863:\tlearn: 0.1244191\ttotal: 5m 56s\tremaining: 56.1s\n",
            "864:\tlearn: 0.1242345\ttotal: 5m 57s\tremaining: 55.7s\n",
            "865:\tlearn: 0.1240935\ttotal: 5m 57s\tremaining: 55.3s\n",
            "866:\tlearn: 0.1239419\ttotal: 5m 57s\tremaining: 54.9s\n",
            "867:\tlearn: 0.1236791\ttotal: 5m 58s\tremaining: 54.5s\n",
            "868:\tlearn: 0.1235898\ttotal: 5m 58s\tremaining: 54s\n",
            "869:\tlearn: 0.1233512\ttotal: 5m 58s\tremaining: 53.6s\n",
            "870:\tlearn: 0.1231694\ttotal: 5m 59s\tremaining: 53.2s\n",
            "871:\tlearn: 0.1230321\ttotal: 5m 59s\tremaining: 52.8s\n",
            "872:\tlearn: 0.1228442\ttotal: 6m\tremaining: 52.4s\n",
            "873:\tlearn: 0.1226431\ttotal: 6m\tremaining: 52s\n",
            "874:\tlearn: 0.1225969\ttotal: 6m 1s\tremaining: 51.6s\n",
            "875:\tlearn: 0.1224811\ttotal: 6m 1s\tremaining: 51.2s\n",
            "876:\tlearn: 0.1222483\ttotal: 6m 2s\tremaining: 50.8s\n",
            "877:\tlearn: 0.1220783\ttotal: 6m 2s\tremaining: 50.4s\n",
            "878:\tlearn: 0.1219378\ttotal: 6m 3s\tremaining: 50s\n",
            "879:\tlearn: 0.1218769\ttotal: 6m 3s\tremaining: 49.6s\n",
            "880:\tlearn: 0.1217572\ttotal: 6m 3s\tremaining: 49.1s\n",
            "881:\tlearn: 0.1214133\ttotal: 6m 4s\tremaining: 48.7s\n",
            "882:\tlearn: 0.1211732\ttotal: 6m 4s\tremaining: 48.3s\n",
            "883:\tlearn: 0.1210220\ttotal: 6m 4s\tremaining: 47.9s\n",
            "884:\tlearn: 0.1208052\ttotal: 6m 5s\tremaining: 47.5s\n",
            "885:\tlearn: 0.1206746\ttotal: 6m 5s\tremaining: 47.1s\n",
            "886:\tlearn: 0.1203997\ttotal: 6m 6s\tremaining: 46.6s\n",
            "887:\tlearn: 0.1202537\ttotal: 6m 6s\tremaining: 46.2s\n",
            "888:\tlearn: 0.1200672\ttotal: 6m 6s\tremaining: 45.8s\n",
            "889:\tlearn: 0.1199432\ttotal: 6m 7s\tremaining: 45.4s\n",
            "890:\tlearn: 0.1197849\ttotal: 6m 7s\tremaining: 45s\n",
            "891:\tlearn: 0.1197509\ttotal: 6m 7s\tremaining: 44.5s\n",
            "892:\tlearn: 0.1195824\ttotal: 6m 8s\tremaining: 44.1s\n",
            "893:\tlearn: 0.1195300\ttotal: 6m 8s\tremaining: 43.7s\n",
            "894:\tlearn: 0.1193303\ttotal: 6m 9s\tremaining: 43.3s\n",
            "895:\tlearn: 0.1191188\ttotal: 6m 9s\tremaining: 42.9s\n",
            "896:\tlearn: 0.1189913\ttotal: 6m 9s\tremaining: 42.5s\n",
            "897:\tlearn: 0.1188344\ttotal: 6m 10s\tremaining: 42s\n",
            "898:\tlearn: 0.1186821\ttotal: 6m 10s\tremaining: 41.6s\n",
            "899:\tlearn: 0.1182747\ttotal: 6m 10s\tremaining: 41.2s\n",
            "900:\tlearn: 0.1180739\ttotal: 6m 11s\tremaining: 40.8s\n",
            "901:\tlearn: 0.1179436\ttotal: 6m 11s\tremaining: 40.4s\n",
            "902:\tlearn: 0.1178912\ttotal: 6m 12s\tremaining: 40s\n",
            "903:\tlearn: 0.1178147\ttotal: 6m 12s\tremaining: 39.6s\n",
            "904:\tlearn: 0.1176308\ttotal: 6m 13s\tremaining: 39.2s\n",
            "905:\tlearn: 0.1175105\ttotal: 6m 13s\tremaining: 38.8s\n",
            "906:\tlearn: 0.1173971\ttotal: 6m 14s\tremaining: 38.4s\n",
            "907:\tlearn: 0.1173158\ttotal: 6m 14s\tremaining: 38s\n",
            "908:\tlearn: 0.1172216\ttotal: 6m 15s\tremaining: 37.5s\n",
            "909:\tlearn: 0.1170642\ttotal: 6m 15s\tremaining: 37.1s\n",
            "910:\tlearn: 0.1168737\ttotal: 6m 15s\tremaining: 36.7s\n",
            "911:\tlearn: 0.1168152\ttotal: 6m 16s\tremaining: 36.3s\n",
            "912:\tlearn: 0.1167520\ttotal: 6m 16s\tremaining: 35.9s\n",
            "913:\tlearn: 0.1164382\ttotal: 6m 16s\tremaining: 35.5s\n",
            "914:\tlearn: 0.1162755\ttotal: 6m 17s\tremaining: 35.1s\n",
            "915:\tlearn: 0.1161318\ttotal: 6m 17s\tremaining: 34.6s\n",
            "916:\tlearn: 0.1159546\ttotal: 6m 18s\tremaining: 34.2s\n",
            "917:\tlearn: 0.1158323\ttotal: 6m 18s\tremaining: 33.8s\n",
            "918:\tlearn: 0.1156475\ttotal: 6m 18s\tremaining: 33.4s\n",
            "919:\tlearn: 0.1155712\ttotal: 6m 19s\tremaining: 33s\n",
            "920:\tlearn: 0.1154282\ttotal: 6m 19s\tremaining: 32.6s\n",
            "921:\tlearn: 0.1153727\ttotal: 6m 19s\tremaining: 32.1s\n",
            "922:\tlearn: 0.1152429\ttotal: 6m 20s\tremaining: 31.7s\n",
            "923:\tlearn: 0.1151094\ttotal: 6m 20s\tremaining: 31.3s\n",
            "924:\tlearn: 0.1150109\ttotal: 6m 21s\tremaining: 30.9s\n",
            "925:\tlearn: 0.1148829\ttotal: 6m 21s\tremaining: 30.5s\n",
            "926:\tlearn: 0.1146439\ttotal: 6m 21s\tremaining: 30.1s\n",
            "927:\tlearn: 0.1144133\ttotal: 6m 22s\tremaining: 29.6s\n",
            "928:\tlearn: 0.1142015\ttotal: 6m 22s\tremaining: 29.2s\n",
            "929:\tlearn: 0.1139991\ttotal: 6m 22s\tremaining: 28.8s\n",
            "930:\tlearn: 0.1138901\ttotal: 6m 23s\tremaining: 28.4s\n",
            "931:\tlearn: 0.1136995\ttotal: 6m 23s\tremaining: 28s\n",
            "932:\tlearn: 0.1136513\ttotal: 6m 24s\tremaining: 27.6s\n",
            "933:\tlearn: 0.1135298\ttotal: 6m 24s\tremaining: 27.2s\n",
            "934:\tlearn: 0.1133759\ttotal: 6m 25s\tremaining: 26.8s\n",
            "935:\tlearn: 0.1132557\ttotal: 6m 26s\tremaining: 26.4s\n",
            "936:\tlearn: 0.1131570\ttotal: 6m 26s\tremaining: 26s\n",
            "937:\tlearn: 0.1129960\ttotal: 6m 26s\tremaining: 25.6s\n",
            "938:\tlearn: 0.1128658\ttotal: 6m 27s\tremaining: 25.1s\n",
            "939:\tlearn: 0.1128125\ttotal: 6m 27s\tremaining: 24.7s\n",
            "940:\tlearn: 0.1126994\ttotal: 6m 27s\tremaining: 24.3s\n",
            "941:\tlearn: 0.1126092\ttotal: 6m 28s\tremaining: 23.9s\n",
            "942:\tlearn: 0.1125041\ttotal: 6m 28s\tremaining: 23.5s\n",
            "943:\tlearn: 0.1124595\ttotal: 6m 29s\tremaining: 23.1s\n",
            "944:\tlearn: 0.1122626\ttotal: 6m 29s\tremaining: 22.7s\n",
            "945:\tlearn: 0.1121310\ttotal: 6m 29s\tremaining: 22.2s\n",
            "946:\tlearn: 0.1119089\ttotal: 6m 30s\tremaining: 21.8s\n",
            "947:\tlearn: 0.1117409\ttotal: 6m 30s\tremaining: 21.4s\n",
            "948:\tlearn: 0.1115877\ttotal: 6m 30s\tremaining: 21s\n",
            "949:\tlearn: 0.1114366\ttotal: 6m 31s\tremaining: 20.6s\n",
            "950:\tlearn: 0.1113874\ttotal: 6m 31s\tremaining: 20.2s\n",
            "951:\tlearn: 0.1112393\ttotal: 6m 32s\tremaining: 19.8s\n",
            "952:\tlearn: 0.1110310\ttotal: 6m 32s\tremaining: 19.4s\n",
            "953:\tlearn: 0.1108936\ttotal: 6m 32s\tremaining: 18.9s\n",
            "954:\tlearn: 0.1107890\ttotal: 6m 33s\tremaining: 18.5s\n",
            "955:\tlearn: 0.1106249\ttotal: 6m 33s\tremaining: 18.1s\n",
            "956:\tlearn: 0.1103872\ttotal: 6m 33s\tremaining: 17.7s\n",
            "957:\tlearn: 0.1102782\ttotal: 6m 34s\tremaining: 17.3s\n",
            "958:\tlearn: 0.1101552\ttotal: 6m 34s\tremaining: 16.9s\n",
            "959:\tlearn: 0.1100610\ttotal: 6m 35s\tremaining: 16.5s\n",
            "960:\tlearn: 0.1099886\ttotal: 6m 35s\tremaining: 16s\n",
            "961:\tlearn: 0.1097842\ttotal: 6m 35s\tremaining: 15.6s\n",
            "962:\tlearn: 0.1096194\ttotal: 6m 36s\tremaining: 15.2s\n",
            "963:\tlearn: 0.1094501\ttotal: 6m 37s\tremaining: 14.8s\n",
            "964:\tlearn: 0.1092113\ttotal: 6m 38s\tremaining: 14.4s\n",
            "965:\tlearn: 0.1090923\ttotal: 6m 38s\tremaining: 14s\n",
            "966:\tlearn: 0.1089636\ttotal: 6m 38s\tremaining: 13.6s\n",
            "967:\tlearn: 0.1088888\ttotal: 6m 39s\tremaining: 13.2s\n",
            "968:\tlearn: 0.1087952\ttotal: 6m 39s\tremaining: 12.8s\n",
            "969:\tlearn: 0.1087657\ttotal: 6m 39s\tremaining: 12.4s\n",
            "970:\tlearn: 0.1085847\ttotal: 6m 40s\tremaining: 12s\n",
            "971:\tlearn: 0.1085531\ttotal: 6m 40s\tremaining: 11.5s\n",
            "972:\tlearn: 0.1085193\ttotal: 6m 41s\tremaining: 11.1s\n",
            "973:\tlearn: 0.1084267\ttotal: 6m 41s\tremaining: 10.7s\n",
            "974:\tlearn: 0.1081373\ttotal: 6m 41s\tremaining: 10.3s\n",
            "975:\tlearn: 0.1080736\ttotal: 6m 42s\tremaining: 9.89s\n",
            "976:\tlearn: 0.1078504\ttotal: 6m 42s\tremaining: 9.48s\n",
            "977:\tlearn: 0.1076752\ttotal: 6m 42s\tremaining: 9.06s\n",
            "978:\tlearn: 0.1075958\ttotal: 6m 43s\tremaining: 8.65s\n",
            "979:\tlearn: 0.1073938\ttotal: 6m 43s\tremaining: 8.24s\n",
            "980:\tlearn: 0.1072047\ttotal: 6m 44s\tremaining: 7.83s\n",
            "981:\tlearn: 0.1069167\ttotal: 6m 44s\tremaining: 7.41s\n",
            "982:\tlearn: 0.1068271\ttotal: 6m 44s\tremaining: 7s\n",
            "983:\tlearn: 0.1066024\ttotal: 6m 45s\tremaining: 6.59s\n",
            "984:\tlearn: 0.1065644\ttotal: 6m 45s\tremaining: 6.17s\n",
            "985:\tlearn: 0.1065067\ttotal: 6m 45s\tremaining: 5.76s\n",
            "986:\tlearn: 0.1063916\ttotal: 6m 46s\tremaining: 5.35s\n",
            "987:\tlearn: 0.1062173\ttotal: 6m 46s\tremaining: 4.94s\n",
            "988:\tlearn: 0.1060102\ttotal: 6m 47s\tremaining: 4.53s\n",
            "989:\tlearn: 0.1059605\ttotal: 6m 47s\tremaining: 4.12s\n",
            "990:\tlearn: 0.1057957\ttotal: 6m 47s\tremaining: 3.7s\n",
            "991:\tlearn: 0.1056473\ttotal: 6m 48s\tremaining: 3.29s\n",
            "992:\tlearn: 0.1055698\ttotal: 6m 49s\tremaining: 2.88s\n",
            "993:\tlearn: 0.1053953\ttotal: 6m 49s\tremaining: 2.47s\n",
            "994:\tlearn: 0.1053289\ttotal: 6m 50s\tremaining: 2.06s\n",
            "995:\tlearn: 0.1052451\ttotal: 6m 50s\tremaining: 1.65s\n",
            "996:\tlearn: 0.1051091\ttotal: 6m 50s\tremaining: 1.24s\n",
            "997:\tlearn: 0.1049768\ttotal: 6m 51s\tremaining: 824ms\n",
            "998:\tlearn: 0.1048472\ttotal: 6m 51s\tremaining: 412ms\n",
            "999:\tlearn: 0.1046483\ttotal: 6m 51s\tremaining: 0us\n"
          ]
        }
      ],
      "source": [
        "models = [\n",
        "    # test set accuracy\n",
        "    LGBMClassifier(verbose=0, thread_count=5, random_seed=37),\n",
        "    # test set accuracy\n",
        "    XGBClassifier(random_state=37),\n",
        "    # test set accuracy  \n",
        "    CatBoostClassifier(verbose=0, random_state=37)]\n",
        "\n",
        "fit = [x.fit(train_x, train_y) for x in models]    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "0bcafdb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "b6298be7-fa4c-4d7f-8671-496b9b7f072b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    423\n",
              "2     73\n",
              "0     39\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def prediction(models, test, mode=None, weights=None):\n",
        "    if mode == \"hard\":\n",
        "        preds = np.asarray([x.predict(test).reshape(-1) for x in models]).T\n",
        "        res = np.apply_along_axis(\n",
        "            lambda x: np.argmax(np.bincount(x, weights=weights)),\n",
        "            axis=1,\n",
        "            arr=preds\n",
        "        )\n",
        "    elif mode == \"soft\":  \n",
        "        preds = np.asarray([x.predict_proba(test) for x in models])\n",
        "        res = np.zeros(preds[0].shape)\n",
        "        for pred, weight in zip(preds, weights):\n",
        "            res = res + pred*weight\n",
        "        res = np.argmax(preds, axis=0) \n",
        "    else:\n",
        "        res = models[0].predict(test)\n",
        "    return res\n",
        "\n",
        "preds = prediction(models, test_x, 'hard', [2,1,2] )\n",
        "\n",
        "sns.countplot(x=preds);   \n",
        "pd.DataFrame(preds).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(preds)\n",
        "pred.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaYMoUn9sV8i",
        "outputId": "86eccc26-2480-4cbf-9696-9682c2bb191e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    423\n",
              "2     73\n",
              "0     39\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "submit['Y_Class'] = preds\n",
        "\n",
        "submit.to_csv('KNNimpute-LXC212.csv', index=False)\n",
        "\n",
        "# sns.countplot(x=pred)\n",
        "# pred.value_counts()"
      ],
      "metadata": {
        "id": "EC061U9PhVxm"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_val_score: CV 검증 set 성능 평가 \n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "score = cross_val_score(fitted, \n",
        "                        train_x, train_y, \n",
        "                        scoring=\"accuracy\", \n",
        "                        cv=5)  # k=5 fold \n",
        "\n",
        "print(\"교차 검증별 정확도:\", np.round(score, 3))\n",
        "print(\"평균 검증 정확도:\", np.mean(score).round(3), \"+/-\", np.std(score).round(3))\n"
      ],
      "metadata": {
        "id": "zHmN98m5Ub-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bda0e6b-4d0c-48d9-b5cf-dfd0cfdd1184"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043319 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026209 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026175 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026474 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Unknown parameter: thread_count\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043804 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "교차 검증별 정확도: [0.758 0.784 0.765 0.752 0.77 ]\n",
            "평균 검증 정확도: 0.766 +/- 0.011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화 --> 성능 down \n"
      ],
      "metadata": {
        "id": "sCzKvjOengHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}