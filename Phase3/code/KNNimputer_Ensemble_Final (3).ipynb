{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ZJBm2amd3Lb5",
      "metadata": {
        "id": "ZJBm2amd3Lb5"
      },
      "source": [
        "# 팀 스마일C 코드 제출\n",
        "* 팀원: 정우섭, 김유민, 김유진, 장동언, 황정묵\n",
        "* PRIVATE SCORE: 0.65887 \n",
        "* PRIVATE RANKING: 36"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CwuGPDTVMXHe",
      "metadata": {
        "id": "CwuGPDTVMXHe"
      },
      "source": [
        "# 개발 환경\n",
        "* OS : Windows11\n",
        "* python: 3.10.10\n",
        "* 라이브러리 버전 : requirements.txt 참조"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QIfodgpc3HP6",
      "metadata": {
        "id": "QIfodgpc3HP6"
      },
      "source": [
        "# 0.Data Load\n",
        "1. install packages\n",
        "2. import libraries and csv data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab709fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ab709fe",
        "outputId": "6786e4e5-5635-49ae-e2b2-1215eefe1b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.4.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (23.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.39.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.9/dist-packages (3.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m683.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (1.7.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install lightgbm\n",
        "!pip install optuna \n",
        "!pip install xgboost\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94682a80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94682a80",
        "outputId": "29de6603-ace9-4570-f7e5-540a57663187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.10.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt   \n",
        "import seaborn as sns \n",
        "\n",
        "# model evaluation, preprocessing \n",
        "import sklearn\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_validate,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score, log_loss\n",
        "\n",
        "# sequential model modeling \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout, Activation\n",
        "from keras import backend as K \n",
        "from keras import regularizers\n",
        "from keras.layers import Dense,Dropout, Activation, BatchNormalization, Conv2D, Flatten  \n",
        "from keras import optimizers, metrics, callbacks\n",
        "from keras.backend import clear_session\n",
        "\n",
        "# optuna Hyper-params tuning\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_parallel_coordinate, plot_contour\n",
        "\n",
        "# ML classification models \n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier,VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# # Google Drive mount\n",
        "# from google.colab import drive \n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0AdADLxT1DoQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AdADLxT1DoQ",
        "outputId": "0ea2137d-1903-470b-f627-c40e627b3538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n"
          ]
        }
      ],
      "source": [
        "# seed fixing for reproduction \n",
        "import torch \n",
        "import random as rn \n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(37) # Seed 고정\n",
        "seed_num=37\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "seed_everything(37)\n",
        "seed_num=37\n",
        "seed=37\n",
        "\n",
        "np.random.seed(seed_num)\n",
        "rn.seed(seed_num) \n",
        "tf.random.set_seed(seed_num)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "class config:   \n",
        "    seed = 37  \n",
        "    device = \"cuda:0\"            \n",
        "\n",
        "def seed_everything(seed: int = 37):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "seed_everything(config.seed)\n",
        "tf.random.set_seed(37) # tensorflow global seed \n",
        "print(config.seed)     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lQROx2fcxIW7",
      "metadata": {
        "id": "lQROx2fcxIW7"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "submit = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "train_x = train_df.drop(columns=['PRODUCT_ID', 'Y_Class','Y_Quality'])\n",
        "train_y = train_df['Y_Class']\n",
        "test_x = test_df.drop(columns=['PRODUCT_ID'])   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wqkW_3EbQxj1",
      "metadata": {
        "id": "wqkW_3EbQxj1"
      },
      "source": [
        "# 1.Data & Features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZK3O2Kd24yP_",
      "metadata": {
        "id": "ZK3O2Kd24yP_"
      },
      "source": [
        "## 1.1 EDA\n",
        "1. feature correlation heatmaps\n",
        "2. feature importance\n",
        "3. feature distribution plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E1vfXTKcK9Dt",
      "metadata": {
        "id": "E1vfXTKcK9Dt"
      },
      "outputs": [],
      "source": [
        "# # random 20 features list (모두 NaN인 컬럼 제외하고, 랜덤 20개 feature의 상관관계 히트맵)\n",
        "# Xs = train_df.iloc[:,4:].columns\n",
        "# null_count = train_df.isnull().sum().to_dict()\n",
        "# cols = pd.DataFrame({i for i in null_count if null_count[i]<250 and i in Xs})\n",
        "# cols_name = list(cols[0])  # not_all_NAN features name in list \n",
        "\n",
        "# import random\n",
        "# a = ['Y_Quality']\n",
        "# for i in range(20):\n",
        "#     num = random.randint(1,3326)\n",
        "#     a.append(cols_name[i])\n",
        "\n",
        "# # heatmap: `random X features` and `Y_Quality` correlation\n",
        "# corr = train_df[a].corr()  # correlation matrix\n",
        "# fig, ax = plt.subplots(figsize=(15,10))\n",
        "# sns.heatmap(corr, annot=True, fmt='.2f', cmap='Blues', linewidths=2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lLsOtCgTSvRA",
      "metadata": {
        "id": "lLsOtCgTSvRA"
      },
      "outputs": [],
      "source": [
        "# # feature 중요도\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# qual_col = ['LINE', 'PRODUCT_CODE']\n",
        "# for i in qual_col:\n",
        "#     le = LabelEncoder()\n",
        "#     le = le.fit(train_x[i])\n",
        "#     train_x[i] = le.transform(train_x[i])\n",
        "#     for label in np.unique(test_x[i]):\n",
        "#         if label not in le.classes_:\n",
        "#             le.classes_ = np.append(le.classes_, label)\n",
        "#     test_x[i] = le.transform(test_x[i])\n",
        "\n",
        "# train_x = train_x.fillna(0)\n",
        "# test_x = test_x.fillna(0)\n",
        "# X_train, X_test, y_train, y_test=train_test_split(train_x,train_y,test_size=0.3,random_state=seed_num)\n",
        "\n",
        "# %matplotlib inline\n",
        "# RF = RandomForestRegressor(random_state=0, max_depth=5, min_samples_leaf=8, min_samples_split=8,n_estimators=200)\n",
        "# RF.fit(X_train, y_train)\n",
        "# ftr_importances_values = RF.feature_importances_\n",
        "# ftr_importances = pd.Series(ftr_importances_values, index=X_train.columns)\n",
        "# ftr_top = ftr_importances.sort_values(ascending=False)[:20]\n",
        " \n",
        "# plt.figure(figsize=(10, 10))\n",
        "# sns.barplot(x=ftr_top, y=ftr_top.index)\n",
        "# plt.show()      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GdugZkQrSvJS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "GdugZkQrSvJS",
        "outputId": "5498c139-a40a-4930-b1f1-0bfe2c092486"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              X_1         X_2    X_3         X_4         X_5    X_6  \\\n",
              "count  838.000000  838.000000  838.0  838.000000  838.000000  838.0   \n",
              "mean     2.755370   94.953461    0.0   45.005967   10.335322    0.0   \n",
              "std      9.155686    4.212002    0.0    0.077059    0.472385    0.0   \n",
              "min      1.000000   87.000000    0.0   45.000000   10.000000    0.0   \n",
              "25%      2.000000   93.000000    0.0   45.000000   10.000000    0.0   \n",
              "50%      2.000000   95.000000    0.0   45.000000   10.000000    0.0   \n",
              "75%      2.000000   98.000000    0.0   45.000000   11.000000    0.0   \n",
              "max    154.000000  102.000000    0.0   46.000000   11.000000    0.0   \n",
              "\n",
              "              X_7         X_8         X_9   X_10  ...      X_3317  \\\n",
              "count  838.000000  838.000000  838.000000  838.0  ...  153.000000   \n",
              "mean    48.587112   10.027446   41.875895    2.0  ...    0.000007   \n",
              "std      3.951187    0.163477   10.499536    0.0  ...    0.000001   \n",
              "min     45.000000   10.000000   31.000000    2.0  ...    0.000004   \n",
              "25%     45.000000   10.000000   31.000000    2.0  ...    0.000007   \n",
              "50%     50.000000   10.000000   52.000000    2.0  ...    0.000007   \n",
              "75%     51.000000   10.000000   52.000000    2.0  ...    0.000008   \n",
              "max     67.000000   11.000000   52.000000    2.0  ...    0.000010   \n",
              "\n",
              "             X_3318      X_3319      X_3320      X_3321      X_3322  \\\n",
              "count  1.530000e+02  153.000000  153.000000  153.000000  153.000000   \n",
              "mean   3.666993e-06    0.190375    0.000021    0.000971    0.000032   \n",
              "std    7.589918e-07    0.000870    0.000011    0.000280    0.000010   \n",
              "min    2.630000e-06    0.188860    0.000007    0.000644    0.000019   \n",
              "25%    3.230000e-06    0.189687    0.000010    0.000672    0.000023   \n",
              "50%    3.420000e-06    0.190287    0.000013    0.001180    0.000028   \n",
              "75%    3.890000e-06    0.191110    0.000032    0.001230    0.000041   \n",
              "max    7.070000e-06    0.193656    0.000035    0.001310    0.000048   \n",
              "\n",
              "           X_3323        X_3324      X_3325      X_3326  \n",
              "count  153.000000  1.530000e+02  153.000000  153.000000  \n",
              "mean     0.000003  2.161843e-06    0.188588    0.000017  \n",
              "std      0.000001  6.646358e-07    0.001444    0.000012  \n",
              "min      0.000002  4.130000e-07    0.185000    0.000003  \n",
              "25%      0.000003  1.570000e-06    0.187000    0.000005  \n",
              "50%      0.000003  2.360000e-06    0.189000    0.000007  \n",
              "75%      0.000004  2.710000e-06    0.189000    0.000030  \n",
              "max      0.000007  3.410000e-06    0.193000    0.000033  \n",
              "\n",
              "[8 rows x 3326 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24da8b34-b304-4a93-a9d7-0a4c34a3230f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_6</th>\n",
              "      <th>X_7</th>\n",
              "      <th>X_8</th>\n",
              "      <th>X_9</th>\n",
              "      <th>X_10</th>\n",
              "      <th>...</th>\n",
              "      <th>X_3317</th>\n",
              "      <th>X_3318</th>\n",
              "      <th>X_3319</th>\n",
              "      <th>X_3320</th>\n",
              "      <th>X_3321</th>\n",
              "      <th>X_3322</th>\n",
              "      <th>X_3323</th>\n",
              "      <th>X_3324</th>\n",
              "      <th>X_3325</th>\n",
              "      <th>X_3326</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.0</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.0</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.000000</td>\n",
              "      <td>838.0</td>\n",
              "      <td>...</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>1.530000e+02</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>1.530000e+02</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>153.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.755370</td>\n",
              "      <td>94.953461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.005967</td>\n",
              "      <td>10.335322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.587112</td>\n",
              "      <td>10.027446</td>\n",
              "      <td>41.875895</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.666993e-06</td>\n",
              "      <td>0.190375</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000971</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>2.161843e-06</td>\n",
              "      <td>0.188588</td>\n",
              "      <td>0.000017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.155686</td>\n",
              "      <td>4.212002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.077059</td>\n",
              "      <td>0.472385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.951187</td>\n",
              "      <td>0.163477</td>\n",
              "      <td>10.499536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>7.589918e-07</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>6.646358e-07</td>\n",
              "      <td>0.001444</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>2.630000e-06</td>\n",
              "      <td>0.188860</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>4.130000e-07</td>\n",
              "      <td>0.185000</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.230000e-06</td>\n",
              "      <td>0.189687</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000672</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.570000e-06</td>\n",
              "      <td>0.187000</td>\n",
              "      <td>0.000005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.420000e-06</td>\n",
              "      <td>0.190287</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.001180</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>2.360000e-06</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>3.890000e-06</td>\n",
              "      <td>0.191110</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.001230</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>2.710000e-06</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>0.000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>154.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>7.070000e-06</td>\n",
              "      <td>0.193656</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3.410000e-06</td>\n",
              "      <td>0.193000</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 3326 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24da8b34-b304-4a93-a9d7-0a4c34a3230f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24da8b34-b304-4a93-a9d7-0a4c34a3230f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24da8b34-b304-4a93-a9d7-0a4c34a3230f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# feature distribution \n",
        "train_x.describe()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fceMKvgyg2Kg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "fceMKvgyg2Kg",
        "outputId": "2448d8fa-5f45-4cf9-83b1-d5893da0bb19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='X_2794', ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# feature histogram with KDE (밀도그래프) \n",
        "# 임의의 feature에 대한 histplot + 밀도 곡선 출력\n",
        "num = random.randint(1,3326)\n",
        "sns.histplot(train_x[f'X_{num}'], kde=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xskVkfufSvDg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "xskVkfufSvDg",
        "outputId": "6daf1349-65ca-4c16-aef0-f89c11d359e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x864 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# visualize random 20 features distribution \n",
        "# imbalanced feature distribution (NO Gaussian distribution shape) --> MinMaxscaler\n",
        "fig, axes = plt.subplots(5,4,figsize=(16,12))\n",
        "ax= axes.flatten()\n",
        "\n",
        "for i in range(20): \n",
        "    num = random.randint(1,3326)\n",
        "    ax[i].hist(train_x[f'X_{num}']);    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xuPOUxQ7Su9m",
      "metadata": {
        "id": "xuPOUxQ7Su9m"
      },
      "source": [
        "## 1.2 Preprocessing\n",
        "1. Label Encoding: categorical values `LINE`, `PRODUCT_CODE`\n",
        "2. Missing values: fillna(0) \n",
        "3. scaling: StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kZ1PM_Zrtzph",
      "metadata": {
        "id": "kZ1PM_Zrtzph"
      },
      "outputs": [],
      "source": [
        "# train_df = pd.read_csv('./train.csv')\n",
        "# test_df = pd.read_csv('./test.csv')\n",
        "# submit = pd.read_csv('./sample_submission.csv')\n",
        "\n",
        "# train_x = train_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Class','Y_Quality'])\n",
        "# train_y = train_df['Y_Class']\n",
        "# test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3AbGp2rBuxuW",
      "metadata": {
        "id": "3AbGp2rBuxuW"
      },
      "outputs": [],
      "source": [
        "# 1) qualitative to quantitative\n",
        "qual_col = ['LINE', 'PRODUCT_CODE']\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()    # one-hot encoding (X): get_dummies(test_df) is not allowed (data leakage)   \n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "    for label in np.unique(test_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_x[i] = le.transform(test_x[i]) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d0cbadd-27ac-4508-8ef3-7e1724447a9c",
      "metadata": {
        "id": "3d0cbadd-27ac-4508-8ef3-7e1724447a9c"
      },
      "outputs": [],
      "source": [
        "# train에서 열의 유일한 값이 nan이거나 모두 같은 값인 경우 해당 열을 제외\n",
        "def remove_col(train_df):\n",
        "    for x in train_x.columns[6:]:\n",
        "        if train_x[x].nunique()==0 or len(train_x[x].unique())==1: # nan 이거나 모두 같은 값인 경우\n",
        "            train_x.drop(columns=[x], inplace=True) \n",
        "            test_x.drop(columns=[x], inplace=True)       \n",
        "    return train_df\n",
        "\n",
        "train = remove_col(train_df) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5268f2be-31a1-4dbd-8783-3ea146519509",
      "metadata": {
        "id": "5268f2be-31a1-4dbd-8783-3ea146519509"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GZ72F04guy3o",
      "metadata": {
        "id": "GZ72F04guy3o"
      },
      "outputs": [],
      "source": [
        "# 2) Missing Values \n",
        "# train_x = train_x.fillna(0)\n",
        "# test_x = test_x.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66d3bf4",
      "metadata": {
        "id": "c66d3bf4"
      },
      "outputs": [],
      "source": [
        "# 3) MinMaxscaling: only `X_???` values (continuous)\n",
        "# Xs = train_x.select_dtypes(include=float).iloc[:,1:].columns.tolist()\n",
        "# scaler = MinMaxScaler().fit(train_x.loc[:, Xs])\n",
        "# train_x.loc[:, Xs] = scaler.transform(train_x.loc[:, Xs])\n",
        "# test_x.loc[:, Xs] = scaler.transform(test_x.loc[:, Xs])\n",
        "\n",
        "# KNN Imputer \n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Impute missing values using KNN imputer on train data\n",
        "imputer = KNNImputer(n_neighbors=5)   # n_neighbors: params\n",
        "imputer.fit(train_x)\n",
        "                                 \n",
        "train_x = imputer.transform(train_x)    \n",
        "test_x = imputer.transform(test_x) \n",
        "train_x = pd.DataFrame(train_x)\n",
        "test_x = pd.DataFrame(test_x)\n",
        "train_x.head()\n",
        "\n",
        "# # Define columns with missing values\n",
        "# missing_cols = ['X_{}'.format(i) for i in range(1, 3327)]\n",
        "\n",
        "# # Impute missing values using KNN imputer on train data\n",
        "# imputer = KNNImputer(n_neighbors=5)\n",
        "# imputer.fit(train_x)\n",
        "            \n",
        "# # imputer = KNNImputer(n_neighbors=1)\n",
        "# # imputer.fit(train)   \n",
        "                                       \n",
        "# train_x = imputer.transform(train_x) \n",
        "# test_x = imputer.transform(test_x)    \n",
        "\n",
        "# train_x = pd.DataFrame(train_x)\n",
        "# test_x = pd.DataFrame(test_x)\n",
        "# train_x.head()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test=train_test_split(train_x,train_y,test_size=0.3,random_state=seed_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06e13eb-9e6f-4f75-8d9a-ec5ab10f076b",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a06e13eb-9e6f-4f75-8d9a-ec5ab10f076b",
        "outputId": "f5d25b5b-5c0b-4aa4-82f7-866898d94871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1132, 3254)\n"
          ]
        }
      ],
      "source": [
        "print(train_x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hIoaatyGu9Zq",
      "metadata": {
        "id": "hIoaatyGu9Zq"
      },
      "source": [
        "# 2.Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GQGMvepMJy87",
      "metadata": {
        "id": "GQGMvepMJy87"
      },
      "source": [
        "## 2.1 ML models\n",
        "- 여러 Machine Learning Classifier 모델들의 test set Accuracy score 도출 \n",
        "    - Ensemble에서 각 모델의 weight(가중치) 정하기 위한 근거로 사용하기 위함\n",
        "1. RandomForestClassifier\n",
        "2. GradientboostingClassiifer\n",
        "3. XGBClassifier\n",
        "4. LGBMClassifier\n",
        "5. CatboostClassifier\n",
        "6. RidgeClassifier\n",
        "7. BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m61QOAHA8lvG",
      "metadata": {
        "id": "m61QOAHA8lvG"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "models = [\n",
        "    RandomForestClassifier(random_state=seed_num), \n",
        "    GradientBoostingClassifier(random_state=seed_num),      \n",
        "    XGBClassifier(random_state=seed_num),\n",
        "    LGBMClassifier(objective='multiclass', random_state=seed_num),\n",
        "    CatBoostClassifier(objective='MultiClass',\n",
        "                                   task_type='GPU',\n",
        "                                   one_hot_max_size=2, random_seed=seed_num,\n",
        "                                   iterations=4000, verbose=False,\n",
        "                                   learning_rate=0.05\n",
        "                                   ),\n",
        "    RidgeClassifierCV(),  # RidgeClassifier: no seed setting argument  \n",
        "    BaggingClassifier(random_state=seed_num)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qfV3aJaS8lvI",
      "metadata": {
        "id": "qfV3aJaS8lvI"
      },
      "outputs": [],
      "source": [
        "# # find weights for each model \n",
        "# model_list = ['RF', 'GBC', 'XGB', 'LGBM', 'Catboost', 'Ridge', 'Bagging']\n",
        "# i=0\n",
        "# model_acc = {}\n",
        "\n",
        "# for model in models:  \n",
        "#     if i == 4: \n",
        "#         preds = model.fit(X_train, y_train).predict(X_test)\n",
        "#         preds = preds.reshape(1,340)\n",
        "#         preds = list(preds[0])\n",
        "#     else: \n",
        "#         preds = model.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "#     globals()[f'preds_{model_list[i]}'] = preds   # set variable name for each model prediction results  \n",
        "  \n",
        "#     score = sklearn.metrics.accuracy_score(y_test, preds)\n",
        "#     model_acc[model_list[i]] = score\n",
        "#     i += 1   \n",
        "\n",
        "# print(model_acc)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PihsvBmKhfOd",
      "metadata": {
        "id": "PihsvBmKhfOd"
      },
      "outputs": [],
      "source": [
        "# # ML models accuracy comparison plot \n",
        "# model_name = list(model_acc.keys())\n",
        "# model_acc = list(model_acc.values())\n",
        "# acc_dic = {'model': model_name, 'acc': model_acc}\n",
        "# acc_df = pd.DataFrame(acc_dic)\n",
        "# acc_df = acc_df.set_index('model')\n",
        "\n",
        "# acc_df.plot(kind='barh', figsize=(14,8),\n",
        "#             title='Model Comparison - accuracy score');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_KIk0bpq4IHj",
      "metadata": {
        "id": "_KIk0bpq4IHj"
      },
      "source": [
        "## 2.2 Sequential MLP \n",
        "* Deep Learning Modeling: Sequential MLP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8wlnknVPi0NX",
      "metadata": {
        "id": "8wlnknVPi0NX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "\n",
        "class MultilayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
        "        \"\"\"\n",
        "        parameters: \n",
        "            input_dim (int): 입력 벡터 크기\n",
        "            hidden_dim1 (int): 첫 번째 Linear 층의 출력 크기\n",
        "            hidden_dim2 (int): 두 번째 Linear 층의 출력 크기 \n",
        "            output_dim (int): 세 번째 Linear 층의 출력 크기 \n",
        "        \"\"\"\n",
        "        super(MultilayerPerceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "       # self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
        "        self.fc4 = nn.Linear(hidden_dim2, output_dim)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"\n",
        "        MLP의 정방향 계산 \n",
        "\n",
        "        parameters:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서\n",
        "                x_in.shape는 (batch, input_dim)\n",
        "            apply_softmax (multiclasses): softmax activation function \n",
        "        return: \n",
        "            result Tensor\n",
        "            tesnor.shape: (batch, output_dim)\n",
        "        \"\"\"\n",
        "        intermediate1 = F.relu(self.fc1(x_in))   # activation function\n",
        "        intermediate2 = F.relu(self.fc2(intermediate1))   # activation function\n",
        "       # intermediate3 = F.relu(self.fc3(intermediate2))   # activation function\n",
        "        output = self.fc4(intermediate2)    \n",
        "\n",
        "\n",
        "        if apply_softmax: \n",
        "            output = F.softmax(output, dim=1)   # output layer: softmax activation function\n",
        "        return output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fp5qXV02kPeC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp5qXV02kPeC",
        "outputId": "289fa6a6-984f-407e-88ec-4dff0dfc5993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilayerPerceptron(\n",
            "  (fc1): Linear(in_features=3254, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=3, bias=True)\n",
            ")\n",
            "Type: torch.FloatTensor\n",
            "shape: torch.Size([256, 3])\n"
          ]
        }
      ],
      "source": [
        "def describe(x): \n",
        "    print(f'Type: {x.type()}')\n",
        "    print(f'shape: {x.shape}')\n",
        "    # print(f'value: {x}') \n",
        "\n",
        "batch_size = 256 \n",
        "input_dim = train_x.shape[-1]\n",
        "hidden_dim1 = 1024\n",
        "hidden_dim2 = 512\n",
        "output_dim = 3 \n",
        "\n",
        "# model design \n",
        "mlp = MultilayerPerceptron(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
        "print(mlp)\n",
        "x_input = torch.rand(batch_size, input_dim)\n",
        "y_output = mlp(x_input, apply_softmax=True)  # result: probabilities format \n",
        "a = y_output\n",
        "describe(y_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FLHA36Z1iEhW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "FLHA36Z1iEhW",
        "outputId": "ded4ad08-6741-47e2-add5-c49a1a1a3c1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "prediction=[]\n",
        "\n",
        "for i in a: \n",
        "    i = list(i)\n",
        "    prediction.append(i.index(max(i)))\n",
        "\n",
        "sns.countplot(x=prediction);    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f3d392b",
      "metadata": {
        "id": "7f3d392b"
      },
      "source": [
        "# 3.Params Optimization\n",
        "1. Optuna\n",
        "2. GridSearch "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee4390b",
      "metadata": {
        "id": "5ee4390b"
      },
      "source": [
        "## 3.1 Light Gradient Boosting\n",
        "1. Optuna\n",
        "    - hyperparameters auto optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29dc0524",
      "metadata": {
        "id": "29dc0524"
      },
      "outputs": [],
      "source": [
        "# def objective(trial, X, y, cv, scoring):\n",
        "#     params = {\n",
        "#         'lambda_l1' : trial.suggest_loguniform('lambda_l1', 1e-8, 1e-1),\n",
        "#         'lambda_l2' : trial.suggest_loguniform('lambda_l2', 1e-8, 1e-1),\n",
        "#         'path_smooth' : trial.suggest_loguniform('path_smooth', 1e-8, 1e-3),\n",
        "#         'num_leaves' : trial.suggest_int('num_leaves', 30, 200),\n",
        "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
        "#         'max_bin' : trial.suggest_int('max_bin', 100, 255),\n",
        "#         'feature_fraction' : trial.suggest_uniform('feature_fraction', 0.5, 0.9),\n",
        "#         'bagging_fraction' : trial.suggest_uniform('bagging_fraction', 0.5, 0.9),\n",
        "#     }\n",
        "#   # Perform cross validation\n",
        "#   # gb_class = GradientBoostingClassifier(**params)\n",
        "#     lgbm_class = LGBMClassifier(**params)\n",
        "\n",
        "#   # Compute scores\n",
        "#     scores = cross_validate(lgbm_class, X, y, cv = cv, scoring = scoring, n_jobs = -1)\n",
        "#     accuracy = scores[\"test_score\"].mean()\n",
        "#     return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c65d30f",
      "metadata": {
        "id": "0c65d30f"
      },
      "source": [
        "- Optimization for params\n",
        "\n",
        "    - K-Fold, trials = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d11262c",
      "metadata": {
        "id": "4d11262c"
      },
      "outputs": [],
      "source": [
        "# sampler = optuna.samplers.TPESampler(seed=10, gpu_properties={'device_id': 0})\n",
        "# study = optuna.create_study(direction = \"maximize\")\n",
        "# study.set_user_attr(\"verbose\", True)\n",
        "\n",
        "# kf = sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=37)\n",
        "\n",
        "# func = lambda trial: objective(trial, X_train, y_train, cv = kf, scoring = \"accuracy\")\n",
        "\n",
        "# # # %%time\n",
        "# # # Start optimizing with 100 trials\n",
        "# study.optimize(func, n_trials = 10,n_jobs=-1)\n",
        "\n",
        "# print(f\"The highest accuracy reached by this study: {(study.best_value) * 100}%.\")\n",
        "# print(\"Best params:\")\n",
        "# for key, value in study.best_params.items():\n",
        "#     print(f\"\\t{key}: {value}\")    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5b7e95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5b7e95",
        "outputId": "5e58d625-b5ad-4c4c-82a8-7413a132c27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.00048021471491299205, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00048021471491299205\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7302696718518357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7302696718518357\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6536282159518209, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6536282159518209\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.021386150387940235, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.021386150387940235\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.38      0.47        53\n",
            "           1       0.77      0.93      0.84       227\n",
            "           2       0.71      0.42      0.53        60\n",
            "\n",
            "    accuracy                           0.75       340\n",
            "   macro avg       0.70      0.57      0.61       340\n",
            "weighted avg       0.74      0.75      0.73       340\n",
            "\n",
            "\n",
            " Optuna :  0.75\n"
          ]
        }
      ],
      "source": [
        "import imblearn\n",
        "\n",
        "params= {'lambda_l1': 0.00048021471491299205,'lambda_l2': 0.021386150387940235,\n",
        "         'path_smooth': 4.976692465226837e-07,'num_leaves': 83,\n",
        "         'min_data_in_leaf': 16,'max_bin': 219,\n",
        "         'feature_fraction': 0.6536282159518209,'bagging_fraction': 0.7302696718518357,}\n",
        "# GBC =  GradientBoostingClassifier(random_state=37, **params,                              \n",
        "#                                   ).fit(X_train, y_train)\n",
        "# preds = GBC.predict(X_test)\n",
        "LGBM =  LGBMClassifier(random_state=37, **params,).fit(X_train, y_train)\n",
        "lgbm_preds = LGBM.predict(X_test)\n",
        "# LGBMClassifier(objective='multiclass', random_state=seed_num)\n",
        "print(classification_report(y_test, lgbm_preds))\n",
        "print(\"\\n Optuna : \", accuracy_score(y_test, lgbm_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f76630f",
      "metadata": {
        "id": "8f76630f"
      },
      "outputs": [],
      "source": [
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_contour\n",
        "#plot_param_importances(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b95ea12-6fbe-4748-87fe-5e7c323218bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b95ea12-6fbe-4748-87fe-5e7c323218bd",
        "outputId": "2ee5f90c-6bad-4569-83bf-970e359ea4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc:  0.75\n"
          ]
        }
      ],
      "source": [
        "RF=RandomForestClassifier(random_state=seed_num).fit(X_train,y_train)\n",
        "rf_pred=RF.predict(X_test)\n",
        "print(\"acc: \",accuracy_score(y_test, lgbm_preds))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "# Change following line to range(NFOLDS) to run & find best params.\n",
        "# for fold_id in range(5, 5):\n",
        "#     print('========== Processing fold', fold_id, '==========')\n",
        "\n",
        "import optuna\n",
        "\n",
        "# 1. 최소화/최대화할 목적함수 정의\n",
        "def objective(trial):\n",
        "\n",
        "# 2. trial object로 하이퍼파라미터 값 추천\n",
        "# 다양한 분류모델을 설정해서 비교할 수 있다.\n",
        "    classifier_name = trial.suggest_categorical('classifier', ['RandomForest'])\n",
        "    # #분류 모델이 SVC일 때\n",
        "    # if classifier_name == 'SVC':\n",
        "    #     svc_c = trial.suggest_loguniform('svc_c', 1e-10, 1e10)\n",
        "    #     classifier_obj = sklearn.svm.SVC(C=svc_c, gamma='auto')\n",
        "    \n",
        "    #분류모델이 랜덤포레스트일 때\n",
        "    # else:\n",
        "    # rf_max_depth = int(trial.suggest_loguniform('rf_max_depth', 2, 32))\n",
        "    # tfidf__analyzer = trial.suggest_categorical('tfidf__analyzer', ['word', 'char', 'char_wb']) \n",
        "    # tfidf__lowercase = trial.suggest_categorical('tfidf__lowercase', [False, True]) \n",
        "    tfidf__max_features = trial.suggest_int('tfidf__max_features', 500, 10_000) \n",
        "    rf__n_estimators = trial.suggest_int('rf__num_estimators', 300, 500) \n",
        "    rf__max_depth = trial.suggest_int('rf__max_depth', 5, 15) \n",
        "    rf__min_samples_split = trial.suggest_int('rf__min_samples_split', 10, 30) \n",
        "    \n",
        "\n",
        "    classifier_obj = sklearn.ensemble.RandomForestClassifier(max_depth=rf__max_depth, \n",
        "                                                             n_estimators=rf__n_estimators,\n",
        "                                                             max_features=tfidf__max_features,\n",
        "                                                             min_samples_split = rf__min_samples_split)\n",
        "    \n",
        "    accuracy = cross_val_score(classifier_obj, train_x, train_y, cv = 5).mean()\n",
        "    return accuracy\n",
        "    \n",
        "# 3. study 오브젝트 생성하고 목적함수 최적화하는 단계\n",
        "# 여기서는 목적함수를 정확도로 설정했기 때문에 최대화를 목표로 하고 있지만, 손실함수의 경우 direction='minimize'로 설정\n",
        "study = optuna.create_study(direction='maximize')\n",
        "# 반복 시행 횟수(trial)는 200번으로\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "# Trial 42 finished with value: 0.7667966161163308 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 17.53243068297166}. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HKgV8Eb5UdBf",
        "outputId": "6a171bf4-474e-4655-9cb1-fe90d5596e4d"
      },
      "id": "HKgV8Eb5UdBf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-03-26 00:29:48,106]\u001b[0m A new study created in memory with name: no-name-b47297d4-2b14-4a0d-8df9-f2ba588601d5\u001b[0m\n",
            "\u001b[32m[I 2023-03-26 00:37:11,811]\u001b[0m Trial 0 finished with value: 0.7517679622626797 and parameters: {'classifier': 'RandomForest', 'tfidf__max_features': 5234, 'rf__num_estimators': 451, 'rf__max_depth': 7, 'rf__min_samples_split': 28}. Best is trial 0 with value: 0.7517679622626797.\u001b[0m\n",
            "\u001b[32m[I 2023-03-26 00:42:04,092]\u001b[0m Trial 1 finished with value: 0.7526412225644225 and parameters: {'classifier': 'RandomForest', 'tfidf__max_features': 9419, 'rf__num_estimators': 369, 'rf__max_depth': 5, 'rf__min_samples_split': 14}. Best is trial 1 with value: 0.7526412225644225.\u001b[0m\n",
            "\u001b[32m[I 2023-03-26 00:52:24,460]\u001b[0m Trial 2 finished with value: 0.7650072121944563 and parameters: {'classifier': 'RandomForest', 'tfidf__max_features': 8804, 'rf__num_estimators': 394, 'rf__max_depth': 14, 'rf__min_samples_split': 21}. Best is trial 2 with value: 0.7650072121944563.\u001b[0m\n",
            "\u001b[32m[I 2023-03-26 00:57:30,506]\u001b[0m Trial 3 finished with value: 0.7597130716151417 and parameters: {'classifier': 'RandomForest', 'tfidf__max_features': 1541, 'rf__num_estimators': 399, 'rf__max_depth': 14, 'rf__min_samples_split': 21}. Best is trial 2 with value: 0.7650072121944563.\u001b[0m\n",
            "\u001b[32m[I 2023-03-26 01:08:38,939]\u001b[0m Trial 4 finished with value: 0.7614790846360766 and parameters: {'classifier': 'RandomForest', 'tfidf__max_features': 9155, 'rf__num_estimators': 399, 'rf__max_depth': 15, 'rf__min_samples_split': 24}. Best is trial 2 with value: 0.7650072121944563.\u001b[0m\n",
            "\u001b[32m[I 2023-03-26 01:21:43,617]\u001b[0m Trial 5 finished with value: 0.7720907566956454 and parameters: {'classifier': 'RandomForest', 'tfidf__max_features': 6321, 'rf__num_estimators': 458, 'rf__max_depth': 15, 'rf__min_samples_split': 14}. Best is trial 5 with value: 0.7720907566956454.\u001b[0m\n",
            "\u001b[33m[W 2023-03-26 01:27:23,198]\u001b[0m Trial 6 failed with parameters: {'classifier': 'RandomForest', 'tfidf__max_features': 2669, 'rf__num_estimators': 328, 'rf__max_depth': 15, 'rf__min_samples_split': 29} because of the following error: KeyboardInterrupt().\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-21-0ed2b57b7711>\", line 35, in objective\n",
            "    accuracy = cross_val_score(classifier_obj, train_x, train_y, cv = 5).mean()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 266, in cross_validate\n",
            "    results = parallel(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1051, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\", line 473, in fit\n",
            "    trees = Parallel(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1051, in __call__\n",
            "    while self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 864, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 782, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\", line 184, in _parallel_build_trees\n",
            "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\", line 889, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\", line 379, in fit\n",
            "    builder.build(self.tree_, X, y, sample_weight)\n",
            "KeyboardInterrupt\n",
            "\u001b[33m[W 2023-03-26 01:27:23,200]\u001b[0m Trial 6 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0ed2b57b7711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# 반복 시행 횟수(trial)는 200번으로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Trial 42 finished with value: 0.7667966161163308 and parameters: {'classifier': 'RandomForest', 'rf_max_depth': 17.53243068297166}.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0ed2b57b7711>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     33\u001b[0m                                                              min_samples_split = rf__min_samples_split)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib \n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Pipeline([('rf', RandomForestClassifier)])\n",
        "def objective(trial):    \n",
        "    \n",
        "    joblib.dump(study, 'study.pkl')\n",
        "    \n",
        "    tfidf__analyzer = trial.suggest_categorical('tfidf__analyzer', ['word', 'char', 'char_wb']) \n",
        "    tfidf__lowercase = trial.suggest_categorical('tfidf__lowercase', [False, True]) \n",
        "    tfidf__max_features = trial.suggest_int('tfidf__max_features', 500, 10_000) \n",
        "    rf__n_estimators = trial.suggest_int('rf__num_estimators', 300, 500) \n",
        "    rf__max_depth = trial.suggest_int('rf__max_depth', 5, 15) \n",
        "    rf__min_samples_split = trial.suggest_int('rf__min_samples_split', 10, 30) \n",
        "    \n",
        "   \n",
        "    \n",
        "\n",
        "    params = {\n",
        "        'tfidf__analyzer': tfidf__analyzer,\n",
        "        'tfidf__lowercase': tfidf__lowercase,\n",
        "        'tfidf__max_features': tfidf__max_features,\n",
        "        'rf__n_estimators': rf__n_estimators,\n",
        "        'rf__max_depth': rf__max_depth,\n",
        "        'rf__min_samples_split': rf__min_samples_split,\n",
        "       \n",
        "    }\n",
        "    \n",
        "    model.set_params(**params)   \n",
        "\n",
        "    return  -np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,scoring='neg_log_loss'))\n",
        "\n",
        "# by default, the direction is to minimizae, but can set it to maximize too\n",
        "#study = optuna.create_study(direction='minimize')\n",
        "study = optuna.create_study()\n",
        "\n",
        "\n",
        "#study.optimize(objective, timeout=3600)\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "\n",
        "# to record the value for the last time\n",
        "joblib.dump(study, 'study.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "OoJiaTLoRp9a",
        "outputId": "1bbe0928-35d4-40fc-b44a-07cec1b5f914"
      },
      "id": "OoJiaTLoRp9a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-03-26 00:23:36,797]\u001b[0m A new study created in memory with name: no-name-0ce01b3b-a59b-4f04-89fb-fae10598cc9e\u001b[0m\n",
            "\u001b[33m[W 2023-03-26 00:23:36,804]\u001b[0m Trial 0 failed with parameters: {'tfidf__analyzer': 'char_wb', 'tfidf__lowercase': False, 'tfidf__max_features': 5827, 'rf__num_estimators': 402, 'rf__max_depth': 5, 'rf__min_samples_split': 15} because of the following error: TypeError(\"get_params() missing 1 required positional argument: 'self'\").\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-20-c7773dabaf25>\", line 30, in objective\n",
            "    model.set_params(**params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 211, in set_params\n",
            "    self._set_params(\"steps\", **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/metaestimators.py\", line 70, in _set_params\n",
            "    super().set_params(**params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 198, in set_params\n",
            "    valid_params = self.get_params(deep=True)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\", line 190, in get_params\n",
            "    return self._get_params(\"steps\", deep=deep)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/metaestimators.py\", line 48, in _get_params\n",
            "    for key, value in estimator.get_params(deep=True).items():\n",
            "TypeError: get_params() missing 1 required positional argument: 'self'\n",
            "\u001b[33m[W 2023-03-26 00:23:36,806]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c7773dabaf25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#study.optimize(objective, timeout=3600)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-c7773dabaf25>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     28\u001b[0m     }\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mPipeline\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mParameter\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_get_params\u001b[0;34m(self, attr, deep)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"%s__%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_params() missing 1 required positional argument: 'self'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF = RandomForestClassifier(max_depth= int(17.53243068297166), \n",
        "                            n_estimators=10,\n",
        "                            random_state=seed_num)"
      ],
      "metadata": {
        "id": "UxM65bskYOBo"
      },
      "id": "UxM65bskYOBo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "38703a67",
      "metadata": {
        "id": "38703a67"
      },
      "source": [
        "### 3.1.1 GridSearch\n",
        "\n",
        "- hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f54098-47e8-4a89-b058-81860acc8f4d",
      "metadata": {
        "id": "c5f54098-47e8-4a89-b058-81860acc8f4d"
      },
      "outputs": [],
      "source": [
        "# CBC = CatBoostClassifier(task_type='GPU', border_count=None)\n",
        "# params_grid = {'iterations': [600, 700, 800, 900, 1000],\n",
        "#                'depth': [4, 5, 6],\n",
        "#                'loss_function': ['MultiClass'],\n",
        "#                'l2_leaf_reg': np.logspace(-20, -19, 3),\n",
        "#                'leaf_estimation_iterations': [10],\n",
        "#                'eval_metric': ['Accuracy'],\n",
        "#                'logging_level':['Silent'],\n",
        "#                'random_seed': [42]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34d37d8",
      "metadata": {
        "id": "f34d37d8"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# estimator = GradientBoostingClassifier(random_state = 37)\n",
        "\n",
        "# param_grid = {\n",
        "#             'n_estimators' : [n_estimators for n_estimators in range(100, 5000, 100)],\n",
        "#             'learning_rate' : [lr * 0.0001 for lr in range(1, 10)],\n",
        "#             'max_depth' : [depth for depth in range(3, 9)],\n",
        "#             'subsample' : [subsample * 0.1 for subsample in range(5, 9, 1)],\n",
        "#             'max_features' : ['auto', 'sqrt', 'log2']\n",
        "#             }\n",
        "\n",
        "# # scoring = 'r2' -> 결정계수로 scoring\n",
        "# grid_GBC = GridSearchCV(estimator, param_grid, scoring = 'r2', n_jobs = -1)\n",
        "# grid_GBC.fit(train_x, train_y)\n",
        "\n",
        "# print('best estimator model: \\n{}'.format(grid_GBC.best_estimator_))\n",
        "# print('\\nbest parameter: \\n{}'.format(grid_GBC.best_params_))\n",
        "# print(\"\\nbest score: \\n{}\".format(grid_GBC.best_score_.round(3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8add53",
      "metadata": {
        "id": "7f8add53"
      },
      "outputs": [],
      "source": [
        "# # GridSearch best parameter \n",
        "# import imblearn\n",
        "\n",
        "# params= {'n_estimators': 1200, 'learning_rate': 0.009147154102399788, \\\n",
        "#         'max_depth': 9, 'subsample': 0.8, 'max_features': 'auto'}\n",
        "# GBC =  GradientBoostingClassifier(random_state=37, **params,                              \n",
        "#                                   ).fit(X_train, y_train)\n",
        "# preds = GBC.predict(X_test)\n",
        "\n",
        "# print(classification_report(y_test, preds))\n",
        "# print(\"\\n Grid : \", accuracy_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-V0IZDs6_S3f",
      "metadata": {
        "id": "-V0IZDs6_S3f"
      },
      "source": [
        "## 3.2 CatBoost\n",
        "1. optuna \n",
        "    - hyperparameters auto optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea05433",
      "metadata": {
        "id": "4ea05433"
      },
      "outputs": [],
      "source": [
        "# def objective(trial):\n",
        "#     params = {\n",
        "#         \"iterations\": 1000,\n",
        "#         \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
        "#         \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
        "#         \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
        "#         \"random_seed\": 42,\n",
        "#         \"eval_metric\": \"Accuracy\",\n",
        "#         \"od_type\": \"Iter\",\n",
        "#         \"od_wait\": 100,\n",
        "#         \"verbose\": 1\n",
        "#     }    \n",
        "\n",
        "\n",
        "#     # iterations=trial.suggest_int(\"iterations\", 100, 1000),\n",
        "#     #     learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
        "#     #     depth=trial.suggest_int(\"depth\", 4, 10),\n",
        "#     #     l2_leaf_reg=trial.suggest_float(\"l2_leaf_reg\", 1e-8, 100.0, log=True),\n",
        "#     #     bootstrap_type=trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\"]),\n",
        "#     #     random_strength=trial.suggest_float(\"random_strength\", 1e-8, 10.0, log=True),\n",
        "#     #     bagging_temperature=trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
        "#     #     od_type=trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
        "#     #     od_wait=trial.suggest_int(\"od_wait\", 10, 50),\n",
        "#     #     verbose=False\n",
        "#     model=CatBoostClassifier(**params)\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     return f1_score(y_test, y_pred, average='macro')\n",
        "     \n",
        "# # # hyper-parameter tuning with OPTUNA  \n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# sampler = TPESampler(seed=37)\n",
        "# study = optuna.create_study(study_name=\"catboost\", direction=\"maximize\", sampler=sampler)\n",
        "# study.set_user_attr(\"verbose\", 1)\n",
        "# study.optimize(objective, n_trials=0,n_jobs=-1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ffdb51",
      "metadata": {
        "id": "a8ffdb51"
      },
      "outputs": [],
      "source": [
        "# print(\"Number of trials: \", len(study.trials))\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "# print(\"  Value: \", trial.value)\n",
        "# print(\"  Params: \",trial.params)\n",
        "\n",
        "# CBC_model = CatBoostClassifier(**trial.params, verbose=False, random_state = 37)\n",
        "# CBC_model.fit(X_train, y_train,verbose=1)\n",
        "# y_pred = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1942cb67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1942cb67",
        "outputId": "857cc054-050f-4f2d-d5b9-fa4c85e8e49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.26      0.37        53\n",
            "           1       0.75      0.94      0.83       227\n",
            "           2       0.72      0.38      0.50        60\n",
            "\n",
            "    accuracy                           0.74       340\n",
            "   macro avg       0.70      0.53      0.57       340\n",
            "weighted avg       0.73      0.74      0.70       340\n",
            "\n",
            "\n",
            " Optuna :  0.7382352941176471\n"
          ]
        }
      ],
      "source": [
        "params=  {'iterations': 857, 'learning_rate': 0.07097207730593516, 'depth': 8, \\\n",
        "        'l2_leaf_reg': 0.00012090525126196811, 'bootstrap_type': 'Bayesian', \\\n",
        "        'random_strength': 5.359110894800412, 'bagging_temperature': 0.7137022569955509, \\\n",
        "        'od_type': 'IncToDec', 'od_wait': 42}\n",
        "CBC = CatBoostClassifier(**params, verbose=0, random_state=37, task_type='GPU')\n",
        "CBC.fit(X_train, y_train)\n",
        "preds_CBC = CBC.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, preds_CBC))\n",
        "print(\"\\n Optuna : \", accuracy_score(y_test, preds_CBC))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eACiKQAXwMSW",
      "metadata": {
        "id": "eACiKQAXwMSW"
      },
      "outputs": [],
      "source": [
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_contour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30ec99b",
      "metadata": {
        "id": "b30ec99b"
      },
      "outputs": [],
      "source": [
        "# plot_param_importances(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "458a5890",
      "metadata": {
        "id": "458a5890"
      },
      "source": [
        "### 3.2.1 GridSearch\n",
        "\n",
        "- hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06e0929",
      "metadata": {
        "id": "c06e0929"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# estimator = CatBoostClassifier(random_state = 37)\n",
        "\n",
        "# param_grid = {\n",
        "#             'iterataions' : [iter for iter in range(100, 1000, 100)],\n",
        "#             'learning_rate' : [lr * 0.0001 for lr in range(1, 10)],\n",
        "#             'depth' : [depth for depth in range(4, 10)],\n",
        "#             'l2_leaf_reg' : [leaf * 0.0000001 for leaf in range(1, 100, 10)],\n",
        "#             'bootstrap_type' : ['Bayesian'],\n",
        "#             'random_strength' : [strength * 0.1 for strength in range(1, 100, 10)],\n",
        "#             'bagging_temperature' : [bag * 0.1 for bag in range(1, 10)],\n",
        "#             'od_type' : ['IncToDec', 'Iter'],\n",
        "#             'od_wait' : [wait for wait in range(10, 50, 4)]\n",
        "#             }\n",
        "\n",
        "# # scoring = 'r2' -> 결정계수로 scoring\n",
        "# grid_CBC = GridSearchCV(estimator, param_grid, scoring = 'r2', n_jobs = -1)\n",
        "# grid_CBC.fit(X_train, y_train)\n",
        "\n",
        "# print('best estimator model: \\n{}'.format(grid_CBC.best_estimator_))\n",
        "# print('\\nbest parameter: \\n{}'.format(grid_CBC.best_params_))\n",
        "# print(\"\\nbest score: \\n{}\".format(grid_CBC.best_score_.round(3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888c2ae5-7555-4a50-a9e9-ff8924957fc8",
      "metadata": {
        "tags": [],
        "id": "888c2ae5-7555-4a50-a9e9-ff8924957fc8"
      },
      "outputs": [],
      "source": [
        "# param_grid={'iterations': [600, 700, 800, 900, 1000],\n",
        "#             'depth': [4, 5, 6],\n",
        "#             'loss_function': ['MultiClass'],\n",
        "#             'l2_leaf_reg': np.logspace(-20, -19, 3),\n",
        "#             'leaf_estimation_iterations': [10],\n",
        "#             'eval_metric': ['Accuracy'],\n",
        "#             'logging_level':['Silent'],\n",
        "#             'random_seed': [42]\n",
        "#            }\n",
        "# catB=CatBoostClassifier()\n",
        "# cat_grid=GridSearchCV(catB,param_grid=param_grid,scoring='accuracy',cv=5,n_jobs=-1)\n",
        "\n",
        "# cat_grid.fit(X_train, y_train,verbose=1)\n",
        "\n",
        "# print(\"Best parameters: \", grid_search.best_params_)\n",
        "# print(\"Best score: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "092912ed",
      "metadata": {
        "id": "092912ed"
      },
      "outputs": [],
      "source": [
        "# params=  {'iterations': 857, 'learning_rate': 0.07097207730593516, 'depth': 8, \\\n",
        "#         'l2_leaf_reg': 0.00012090525126196811, 'bootstrap_type': 'Bayesian', \\\n",
        "#         'random_strength': 5.359110894800412, 'bagging_temperature': 0.7137022569955509, \\\n",
        "#         'od_type': 'IncToDec', 'od_wait': 42}\n",
        "# CBC = CatBoostClassifier(**paarams, verbose=False, random_state=37)\n",
        "# CBC.fit(X_train, y_train)\n",
        "# preds_CBC = CBC.predict(X_test)\n",
        "\n",
        "# print(classification_report(y_test, preds_CBC))\n",
        "# print(\"\\n Grid : \", accuracy_score(y_test, preds_CBC))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o8N-QHuIvNN3",
      "metadata": {
        "id": "o8N-QHuIvNN3"
      },
      "source": [
        "# 4.Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe15f1a",
      "metadata": {
        "id": "2fe15f1a"
      },
      "source": [
        "## 4.1 VotingClassifier\n",
        "1. 3-ensemble Modle\n",
        "2. Cross-Validation 구축 후 성능 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vm8q0p4Hyzg2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm8q0p4Hyzg2",
        "outputId": "ce4faed5-fe78-485d-fd8b-b3b3a933e198",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] lambda_l1 is set=0.00048021471491299205, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00048021471491299205\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7302696718518357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7302696718518357\n",
            "[LightGBM] [Warning] feature_fraction is set=0.6536282159518209, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6536282159518209\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.021386150387940235, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.021386150387940235\n"
          ]
        }
      ],
      "source": [
        "models=[CBC,RF,LGBM]   \n",
        "fit= [x.fit(train_x, train_y) for x in models]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bcafdb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0bcafdb3",
        "outputId": "e543ae93-0c7e-4710-a751-8b011455bb61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def prediction(models, test, mode=None, weights=None):\n",
        "    if mode == \"hard\":\n",
        "        preds = np.asarray([x.predict(test).reshape(-1) for x in models]).T\n",
        "        res = np.apply_along_axis(\n",
        "            lambda x: np.argmax(np.bincount(x, weights=weights)),\n",
        "            axis=1,\n",
        "            arr=preds\n",
        "        )  \n",
        "    elif mode == \"soft\":  \n",
        "        preds = np.asarray([x.predict_proba(test) for x in models])\n",
        "        res = np.zeros(preds[0].shape)\n",
        "        for pred, weight in zip(preds, weights):\n",
        "            res = res + pred*weight\n",
        "        res = np.argmax(preds, axis=0) \n",
        "    else:\n",
        "        res = models[0].predict(test)\n",
        "    return res\n",
        "\n",
        "preds = prediction(models, test_x, 'hard', [2,5,4] )\n",
        "\n",
        "sns.countplot(x=preds);   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KUOHpt3z847x",
      "metadata": {
        "id": "KUOHpt3z847x"
      },
      "source": [
        "## 4.2 Validation Score\n",
        "1. train.csv에서 split된 test set accuracy 100% 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z3UesEBQ1r8z",
      "metadata": {
        "id": "Z3UesEBQ1r8z"
      },
      "outputs": [],
      "source": [
        "voting_model = sklearn.ensemble.VotingClassifier(estimators=[\n",
        "                ('CatBoostClassifier', CBC),\n",
        "                ('RandomForest', RF),\n",
        "                ('LGBM', LGBM)], \n",
        "                voting='hard', weights=[2,1,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TgLWsUI2A25b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgLWsUI2A25b",
        "outputId": "24b425ef-66a4-4329-fdac-afecd57bfd61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "val_preds = prediction(models, X_test, 'hard', [2,1,2])\n",
        "val_score= sklearn.metrics.accuracy_score(y_test, val_preds)\n",
        "val_score  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zbNtWowN78mX",
      "metadata": {
        "id": "zbNtWowN78mX"
      },
      "source": [
        "# 5.Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YQHmg0PCJetf",
      "metadata": {
        "id": "YQHmg0PCJetf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21efcb4c-4117-49b4-857a-2636fadc8351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    414\n",
              "2     77\n",
              "0     44\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "submit = pd.read_csv('sample_submission.csv')\n",
        "submit['Y_Class'] = preds\n",
        "\n",
        "submit.to_csv('KNNimputerDropNA-CRL254RFoptuna.csv', index=False)\n",
        "pd.DataFrame(preds).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "utf4-GCG5REy",
      "metadata": {
        "id": "utf4-GCG5REy"
      },
      "source": [
        "# 6.References\n",
        "PPT에 기재하였습니다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5sg6EQYMj_P",
      "metadata": {
        "id": "f5sg6EQYMj_P"
      },
      "source": [
        "# THE END"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}